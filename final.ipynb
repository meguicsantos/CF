{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66809092",
   "metadata": {},
   "source": [
    "## RNN Integration Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b061868",
   "metadata": {},
   "source": [
    "Integration task in **recurrent neural network** with:\n",
    "- a reLU function\n",
    "- backpropagating method\n",
    "- MSE error\n",
    "- LSTM architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f9502",
   "metadata": {},
   "source": [
    "implement input trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc08255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Trial: tensor([1., 0.])\n",
      "Target: tensor([[ 0.6852, -0.6041],\n",
      "        [ 0.0495, -1.4055]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#number of trials and sequence length\n",
    "num_trials = 100\n",
    "sequence_length = 2\n",
    "#Random sequence of 0 and 1\n",
    "input_trials = torch.randint(2, size=(num_trials, sequence_length)).float()\n",
    "\n",
    "#Generation of random input trials\n",
    "#input_trials = []\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    #Cumulative sum of the sequenced\n",
    "    target = torch.cumsum(sequence, dim=0)\n",
    "    #add the sequence and target to the input trials\n",
    "    targets.append(target)\n",
    "\n",
    "#Convert input trials and targets to tensors\n",
    "targets = torch.stack(targets).float()\n",
    "\n",
    "sample_index = 0\n",
    "print(\"Input Trial:\", input_trials[sample_index])\n",
    "print(\"Target:\", targets[sample_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d7cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([100, 2, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Input: tensor([[ 0.1210, -0.4106],\n",
      "        [-0.4351,  0.6871]])\n",
      "Predicted Output: tensor([0.0398, 0.0124])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#LSTM-based integration model\n",
    "class IntegrationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(IntegrationModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "       \n",
    "    def forward(self, input_seq):\n",
    "        _, (hidden, _) = self.lstm(input_seq)\n",
    "        output = self.fc(self.relu(hidden[-1]))\n",
    "        return output\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "input_size = 2  #size of the input sequence\n",
    "hidden_size = 32  #nr of hidden units in the LSTM layer\n",
    "output_size = 2  #size of the output (predicted integrated value)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "model = IntegrationModel(input_size, hidden_size, output_size)\n",
    "\n",
    "#loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#adam optimizer adjust the learning rate based on the momentum of the gradient\n",
    "#can accelarate the gradient descent, no guarantee to converge\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=learning_rate) #????\n",
    "\n",
    "x_axis = torch.arange(0,num_epochs)\n",
    "loss_vector_adam = []\n",
    "#print(outputs)\n",
    "#----------------------------------\n",
    "#Training loop with adam optimizer\n",
    "#----------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    #forward pass\n",
    "    outputs = model(input_trials)\n",
    "    #print('outputs = ',outputs)\n",
    "\n",
    "    optimizer_adam.zero_grad()#set the gradients to zero\n",
    "    #loss calculous\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    #Backpropagation and optimization\n",
    "    loss.backward() #backpropagating\n",
    "    optimizer_adam.step() #parameter update\n",
    "    \n",
    "    loss_vector_adam.append(loss.item())\n",
    "    #tracking training progress\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "loss_vector_sgd = []\n",
    "#using a regular stochastic gradient descent\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#----------------------------------\n",
    "#Training loop with regular stochastic gradient descent\n",
    "#----------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    #forward pass\n",
    "    outputs = model(input_trials)\n",
    "\n",
    "    optimizer_sgd.zero_grad()#set the gradients to zero\n",
    "    #loss calculous\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    #Backpropagation and optimization\n",
    "    loss.backward() #backpropagating\n",
    "    optimizer_sgd.step() #parameter update\n",
    "    \n",
    "    loss_vector_sgd.append(loss.item())\n",
    "    #tracking training progress\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector_adam,label='Adam Optimizer')\n",
    "plt.plot(x_axis,loss_vector_sgd,label='regular stochastic gradient descent')\n",
    "plt.title('Comparison between Adam Optimizer & regular stochastic gradient descent')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#test the  model\n",
    "model.eval()\n",
    "test_input = torch.randn(sequence_length, input_size) #random input\n",
    "with torch.no_grad(): #temporarily disable gradient computation\n",
    "    predicted_output = model(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", predicted_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825672e",
   "metadata": {},
   "source": [
    "# ___________22/06 __________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed23828",
   "metadata": {},
   "source": [
    "## Using Vanilla architecture with a single layer and ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be835678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([100, 1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "Test Input: tensor([[0.2893]])\n",
      "Predicted Output: tensor([0.0795])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------------------------------------------\n",
    "#--------- 22/06 - updated version ---------------\n",
    "#-------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define Vanilla RNN model\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs, _ = self.rnn(inputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        #print(outputs[ -1,:])\n",
    "        logits = self.fc(outputs[-1,:])  # Take the last output of the sequence\n",
    "        output = torch.relu(logits)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Define the training data\n",
    "num_trials = 100\n",
    "sequence_length = 1\n",
    "input_size = 1\n",
    "input_trials = torch.randint(2, size=(num_trials, sequence_length)).float()\n",
    "#print('input_trials=',input_trials)\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    #print('sequence=',sequence)\n",
    "    target = torch.cumsum(sequence, dim=0)[-1] #turns positive\n",
    "    \n",
    "    targets.append(target)\n",
    "    #print('targer=',targets)\n",
    "targets = torch.stack(targets).unsqueeze(1).float()\n",
    "#print('targets=',targets)\n",
    "# Hyperparameters\n",
    "hidden_size = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the Vanilla RNN model\n",
    "model = VanillaRNN(input_size, hidden_size)\n",
    "#print('model=',model(input_trials))\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "x_axis = torch.arange(0,num_epochs)\n",
    "loss_vector = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    logits = model(input_trials)\n",
    "    #print('logits=',logits)\n",
    "    #print('targets=',targets)\n",
    "    loss = criterion(logits, targets)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vector.append(loss.item())\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector)\n",
    "plt.title('Loss in vanilla RNN')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "#set the initial state\n",
    "batch_size = num_trials\n",
    "initial_hidden = torch.zeros(1, batch_size, hidden_size)\n",
    "print(initial_hidden)\n",
    "\n",
    "\n",
    "#test the  model\n",
    "model.eval()\n",
    "test_input = torch.randn(sequence_length, input_size) #random input\n",
    "\n",
    "with torch.no_grad(): #temporarily disable gradient computation\n",
    "    predicted_output = model(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e09f7",
   "metadata": {},
   "source": [
    "## predefined Vanilla RNNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aea9f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaRNN(\n",
      "  (rnn): RNN(3, 2)\n",
      "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (transform): ReLU()\n",
      ")\n",
      "tensor([[0.7840]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.all_weights[0][0][:] = torch.tensor(W_in, dtype=torch.float)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.all_weights[0][1][:] = torch.tensor(W_hh, dtype=torch.float)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.all_weights[0][2][:] =  torch.tensor(b_hh, dtype=torch.float)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.transform = transform_function\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.transform(outputs)  # Apply the transform function\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function=nn.ReLU()):\n",
    "    \"\"\"\n",
    "    Input, recurrent and output weight and recurrent and output biases need to be given\n",
    "    Returns PyTorch RNN with given weights.\n",
    "    \"\"\"\n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0]\n",
    "\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function)\n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.all_weights[0][0][:] = torch.tensor(W_in, dtype=torch.float)\n",
    "        rnn_model.rnn.all_weights[0][1][:] = torch.tensor(W_hh, dtype=torch.float)\n",
    "        rnn_model.rnn.all_weights[0][2][:] =  torch.tensor(b_hh, dtype=torch.float)\n",
    "        rnn_model.rnn.all_weights[0][3][:] =  torch.zeros((N_rec), dtype=torch.float)\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Define the network parameters as PyTorch tensors\n",
    "W_in = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]], dtype=torch.float)  # Input weights\n",
    "W_hh = torch.tensor([[0.7, 0.8], [0.9, 1.0]], dtype=torch.float)  # Recurrent weights\n",
    "W_out = torch.tensor([[0.2, 0.4]], dtype=torch.float)  # Output weights\n",
    "b_hh = torch.tensor([0.1, 0.2], dtype=torch.float)  # Recurrent biases\n",
    "b_out = torch.tensor([0.3], dtype=torch.float)  # Output biases\n",
    "\n",
    "# Create an RNN model using the network parameters and ReLU as the transform function\n",
    "rnn_model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, nn.ReLU())\n",
    "\n",
    "# Print the model architecture\n",
    "print(rnn_model)\n",
    "\n",
    "# Perform forward pass with sample input\n",
    "input_data = torch.tensor([[[0.2, 0.4, 0.6], [0.3, 0.5, 0.7]]], dtype=torch.float)  # Sample input\n",
    "output, _ = rnn_model(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c7f6e",
   "metadata": {},
   "source": [
    "### Vanilla RNN with initializing the hidden state and linear in ReLU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "838645fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_trials= tensor([[[1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.]]])\n",
      "Test Input: tensor([[ 0.1095,  0.7589],\n",
      "        [-0.0199,  0.8991]])\n",
      "Predicted Output: (tensor([[-0.1305]]), tensor([[[0.1388, 0.0000, 0.0522, 0.2466, 0.0725, 0.1578, 0.1119, 0.0000,\n",
      "          0.0000, 0.0000, 0.0899, 0.0248, 0.0000, 0.1823, 0.0000, 0.1904,\n",
      "          0.0687, 0.0000, 0.0344, 0.2508, 0.0423, 0.3811, 0.0000, 0.0000,\n",
      "          0.0000, 0.0307, 0.0508, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1741, 0.0000, 0.0735, 0.2546, 0.0686, 0.1556, 0.1468, 0.0000,\n",
      "          0.0000, 0.0000, 0.0991, 0.0247, 0.0000, 0.2013, 0.0000, 0.1808,\n",
      "          0.0647, 0.0000, 0.0608, 0.2597, 0.0309, 0.3727, 0.0000, 0.0000,\n",
      "          0.0000, 0.0249, 0.0565, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([100, 2, 1])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size,num_layers = 1,nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.relu(outputs)\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "\n",
    "#training data\n",
    "num_trials = 100\n",
    "sequence_length = 2\n",
    "input_size = 2\n",
    "input_trials = torch.randint(2, size=(sequence_length, batch_size, input_size)).float()\n",
    "#print('input_trials = ', input_trials)\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    target = torch.cumsum(sequence, dim=0)[-1]\n",
    "    targets.append(target)\n",
    "targets = torch.stack(targets).unsqueeze(2).float()\n",
    "#print('targets= ',targets)\n",
    "\n",
    "#Hyperparameters\n",
    "hidden_size = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "#create the Vanilla RNN model\n",
    "model = VanillaRNN(input_size, hidden_size)\n",
    "\n",
    "#loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print('input_trials=',input_trials)\n",
    "x_axis = torch.arange(0,num_epochs)\n",
    "loss_vector = []\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    hidden = None\n",
    "    logits, hidden = model(input_trials, hidden)\n",
    "    \n",
    "    \n",
    "    loss = criterion(logits, targets)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vector.append(loss.item())\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "    \n",
    "#print loss function\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector)\n",
    "plt.title('Loss in vanilla RNN')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "#set the initial state\n",
    "batch_size = num_trials\n",
    "initial_hidden = torch.zeros(1, batch_size, hidden_size)\n",
    "\n",
    "#test the  model\n",
    "model.eval()\n",
    "test_input = torch.randn(sequence_length, input_size) #random input\n",
    "with torch.no_grad():\n",
    "    predicted_output = model(test_input.unsqueeze(1).transpose(0, 1))\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437a91b",
   "metadata": {},
   "source": [
    "# 23/06 - updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229115bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_in= 10 - nmero de colunas do input\n",
      "N_out= 5 - nmero de linhas do output\n",
      "N_rec= 20 - nmero de linhas da camada recurrente\n",
      "Epoch 1/10, Average Loss: 73.19563674926758\n",
      "Epoch 2/10, Average Loss: 6.254050374031067\n",
      "Epoch 3/10, Average Loss: 0.3530493453145027\n",
      "Epoch 4/10, Average Loss: 0.031887530349195004\n",
      "Epoch 5/10, Average Loss: 0.003071403072681278\n",
      "Epoch 6/10, Average Loss: 0.0003072424078709446\n",
      "Epoch 7/10, Average Loss: 2.9642592153322767e-05\n",
      "Epoch 8/10, Average Loss: 3.0416988465731265e-06\n",
      "Epoch 9/10, Average Loss: 2.88157782080134e-07\n",
      "Epoch 10/10, Average Loss: 3.0614388801808445e-08\n",
      "Testing Loss: 23.038602471351624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.transform = transform_function\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.transform(outputs)  # Apply the transform function\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "#initializes its weights and biases based on the provided parameters\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function=nn.ReLU()):\n",
    "    \"\"\"\n",
    "    Input, recurrent and output weight and recurrent and output biases need to be given\n",
    "    Returns PyTorch RNN with given weights.\n",
    "    \"\"\"\n",
    "    N_in = W_in.shape[1]\n",
    "    print('N_in=',N_in,'- nmero de colunas do input')\n",
    "    N_out = W_out.shape[0]\n",
    "    print('N_out=',N_out,'- nmero de linhas do output')\n",
    "    N_rec = W_hh.shape[0]\n",
    "    print('N_rec=',N_rec,'- nmero de linhas da camada recurrente')\n",
    "\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function)\n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_hh_l0 = nn.Parameter(torch.zeros((N_rec), dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Initialize the model with desired weights and biases\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "\n",
    "W_in = torch.randn(hidden_size, input_size)\n",
    "W_hh = torch.randn(hidden_size, hidden_size)\n",
    "W_out = torch.randn(output_size, hidden_size)\n",
    "b_hh = torch.randn(hidden_size)\n",
    "b_out = torch.randn(output_size)\n",
    "\n",
    "model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out)\n",
    "\n",
    "# Define the training and testing datasets (example)\n",
    "train_dataset = [(torch.randn(1, 1, input_size), torch.tensor([1, 0, 0, 0, 0], dtype=torch.float32)),\n",
    "                 (torch.randn(1, 1, input_size), torch.tensor([0, 1, 0, 0, 0], dtype=torch.float32))]\n",
    "\n",
    "test_dataset = [(torch.randn(1, 1, input_size), torch.tensor([1, 0, 0, 0, 0], dtype=torch.float32)),\n",
    "                (torch.randn(1, 1, input_size), torch.tensor([0, 1, 0, 0, 0], dtype=torch.float32))]\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "x_axis = torch.arange(0,len(train_dataset)*num_epochs)\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, targets in train_dataset:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _ = model(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        loss_vector.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "# Testing\n",
    "total_loss = 0\n",
    "\n",
    "for inputs, targets in test_dataset:\n",
    "    # Forward pass\n",
    "    outputs, _ = model(inputs)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs.squeeze(), targets)\n",
    "    \n",
    "    total_loss += loss.item()\n",
    "\n",
    "avg_loss = total_loss / len(test_dataset)\n",
    "print(f\"Testing Loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector)\n",
    "plt.title('Loss in vanilla RNN')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527da8d",
   "metadata": {},
   "source": [
    "## USING THE PARAMETERS IN THE MANUSCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24ebfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_in= 2 - nmero de colunas do input\n",
      "N_out= 2 - nmero de linhas do output\n",
      "N_rec= 2 - nmero de linhas da camada recurrente\n",
      "VanillaRNN(\n",
      "  (rnn): RNN(2, 2)\n",
      "  (fc): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (transform): ReLU()\n",
      ")\n",
      "input_sequence =  tensor([[[-0.4976,  1.1204]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1, 2].  Tensor sizes: [2, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 74>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     77\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 78\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target_output)\n\u001b[0;32m     80\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mVanillaRNN.forward\u001b[1;34m(self, inputs, hidden)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 14\u001b[0m     outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(outputs)  \u001b[38;5;66;03m# Apply the transform function\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(outputs[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:513\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    509\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_tanh(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    510\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m    511\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1, 2].  Tensor sizes: [2, 1]"
     ]
    }
   ],
   "source": [
    "#-------------isnt running!!!!!!!!!!-----------------\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.transform = transform_function\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.transform(outputs)  # Apply the transform function\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "#initializes its weights and biases based on the provided parameters\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function=nn.ReLU()):\n",
    "    \"\"\"\n",
    "    Input, recurrent and output weight and recurrent and output biases need to be given\n",
    "    Returns PyTorch RNN with given weights.\n",
    "    \"\"\"\n",
    "    N_in = W_in.shape[1]\n",
    "    print('N_in=',N_in,'- nmero de colunas do input')\n",
    "    N_out = W_out.shape[0]\n",
    "    print('N_out=',N_out,'- nmero de linhas do output')\n",
    "    N_rec = W_hh.shape[0]\n",
    "    print('N_rec=',N_rec,'- nmero de linhas da camada recurrente')\n",
    "\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function)\n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_hh_l0 = nn.Parameter(torch.zeros((N_rec), dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Initialize the model with desired weights and biases\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 2\n",
    "\n",
    "# IDENTITY RNN\n",
    "W_in = torch.eye(input_size)\n",
    "W_hh = torch.eye(hidden_size)\n",
    "W_out = torch.Tensor(np.array([[-1],[1]]))\n",
    "b_hh = torch.Tensor(np.array([[0],[0]]))\n",
    "b_out = 0\n",
    "\n",
    "model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Generate a single training sample\n",
    "batch_size = 1\n",
    "input_length = 1\n",
    "input_sequence = torch.randn(batch_size, input_length, input_size)\n",
    "print('input_sequence = ',input_sequence)\n",
    "target_output = torch.tensor([[1,0]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_sequence)\n",
    "    loss = criterion(output, target_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_vector.append(loss.item())\n",
    "\n",
    "    # Print the loss for monitoring\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ab0d3",
   "metadata": {},
   "source": [
    "# 26/06 monday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb8a0c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_inn= torch.Size([2, 2])\n",
      "W_hh= torch.Size([2, 2])\n",
      "w_out= torch.Size([1, 2])\n",
      "b_hh= torch.Size([1, 2])\n",
      "b_out= torch.Size([1])\n",
      "Input Sequence =  tensor([[[-0.7798,  1.1448],\n",
      "         [-0.0938, -2.6223],\n",
      "         [-0.9053,  0.1386]]])\n",
      "hidden state =  tensor([[0., 0.]])\n",
      "Target =  tensor([[[ 0.8834],\n",
      "         [-0.8708],\n",
      "         [ 0.1221]]])\n",
      "Epoch: 1, Loss: 1.085811972618103\n",
      "Epoch: 2, Loss: 0.9576928019523621\n",
      "Epoch: 3, Loss: 0.8473827242851257\n",
      "Epoch: 4, Loss: 0.7517366409301758\n",
      "Epoch: 5, Loss: 0.6683130860328674\n",
      "Epoch: 6, Loss: 0.5951871275901794\n",
      "Epoch: 7, Loss: 0.5308206677436829\n",
      "Epoch: 8, Loss: 0.47396770119667053\n",
      "Epoch: 9, Loss: 0.4236074388027191\n",
      "Epoch: 10, Loss: 0.4126988649368286\n",
      "Test Outputs:\n",
      "tensor([[[1.3129],\n",
      "         [0.0212],\n",
      "         [0.3958]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_in.weight = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.weight = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.bias = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([1, 3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_in.weight = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.weight = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.bias = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "#vanilla structure normal\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function='relu'):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.transform_function = transform_function\n",
    "        self.fc_in = nn.Linear(input_size, hidden_size)\n",
    "        self.fc_hh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        activation = F.relu\n",
    "        hidden = activation(self.fc_in(input) + self.fc_hh(hidden))\n",
    "        output = self.fc_out(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function='relu'):\n",
    "    \n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0]\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function=transform_function)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rnn_model.fc_in.weight = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.fc_hh.weight = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.fc_hh.bias = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.fc_out.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc_out.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "\n",
    "    return rnn_model\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------parameters-------------\n",
    "#----------------------------------------\n",
    "\n",
    "#input weight matrix\n",
    "W_in = torch.eye(2)\n",
    "print('W_inn=',W_in.shape)\n",
    "\n",
    "#recurrent weight matrix\n",
    "W_hh = torch.eye(2)\n",
    "print('W_hh=',W_hh.shape)\n",
    "\n",
    "#output weitght matrix\n",
    "W_out = torch.Tensor(np.array([[-1,1]]))\n",
    "print('w_out=',W_out.shape)\n",
    "\n",
    "#recurrent bias\n",
    "b_hh = torch.Tensor(np.array([[0,0]]))\n",
    "print('b_hh=',b_hh.shape)\n",
    "\n",
    "#output bias\n",
    "b_out = torch.Tensor([0])\n",
    "print('b_out=',b_out.shape)\n",
    "\n",
    "rnn_model = make_rnn_from_networkparameters(W_in,W_hh,W_out,b_hh,b_out)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "#input_sequence = torch.Tensor([[1, 0], [0, 1], [1, 1]])  \n",
    "input_size = 2\n",
    "input_length = 3\n",
    "batch_size= 1\n",
    "output_size = 1\n",
    "input_sequence = torch.randn(batch_size, input_length, input_size)\n",
    "print('Input Sequence = ',input_sequence)\n",
    "\n",
    "#inicialize the hidden state\n",
    "hidden_state = rnn_model.init_hidden(input_sequence.size(0)) \n",
    "print('hidden state = ',hidden_state)\n",
    "\n",
    "target_output = torch.randn(batch_size,input_length,output_size)\n",
    "print('Target = ',target_output)\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------train-------------------\n",
    "#----------------------------------------\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  #Clear gradients\n",
    "    hidden_state = rnn_model.init_hidden(input_sequence.size(0))  #initialize the hidden state for each epoch\n",
    "    outputs, hidden_state = rnn_model(input_sequence, hidden_state)  #forward pass\n",
    "    loss = criterion(outputs, target_sequence)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    loss_vector.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "#save the training model  \n",
    "torch.save(rnn_model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "#load the trained model\n",
    "rnn_model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out)\n",
    "rnn_model.load_state_dict(torch.load('trained_model.pth'))\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------test-------------------\n",
    "#----------------------------------------\n",
    "#evaluation mode\n",
    "rnn_model.eval()\n",
    "\n",
    "#forward pass on test input\n",
    "test_outputs, _ = rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0)))\n",
    "\n",
    "# Print the test outputs\n",
    "print(\"Test Outputs:\")\n",
    "print(test_outputs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e07c2",
   "metadata": {},
   "source": [
    "## Same above but ussing pytorch.nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c18496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_inn= torch.Size([2, 2])\n",
      "W_hh= torch.Size([2, 2])\n",
      "w_out= torch.Size([1, 2])\n",
      "b_hh= torch.Size([1, 2])\n",
      "b_out= torch.Size([1])\n",
      "Input Sequence =  tensor([[[-0.6708,  0.0159],\n",
      "         [ 1.3870,  1.2741],\n",
      "         [ 0.1584,  0.3754]]])\n",
      "hidden state =  tensor([[[0., 0.]]])\n",
      "Target =  tensor([[[-0.4692],\n",
      "         [ 0.4328],\n",
      "         [-0.4403]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1654104985.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1654104985.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1654104985.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1654104985.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1654104985.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 3, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/100, Loss: 0.17536307871341705\n",
      "Test Outputs:\n",
      "tensor([[-0.1463]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfPUlEQVR4nO3deZRcZ33m8e9TvVnqliX1YmNasiWwbBAgGyKLfSAsQSYEsWSCbAzEQ8bHTBxgwhCbABkIzBAfEg7jICI8xNgEsCcJBhQjYxizmAECbhPjFRHhTS3ZuLVZ1t7Lb/64t7pLpepWt9S3S6r3+ZxTp+9973tv/a6XeupubykiMDOzdJXqXYCZmdWXg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAmt4ktZK+nC966gk6aWSNlTMPyTpVfn0RyR9qX7VWWocBDZjKj/sZlJEXBoRH5vqepI+J+mLNdqXSTogqfMYavphRJx9tOuPR9L3Je2XtFvSVkk3SjqtYvlHJIWk/1jR1py3Lcrnr83nV1T0OVOSHzpqUA4Cs/FdC7xJUntV+9uBmyJi+8yXNCmXRUQHcCbQAfx11fLtwF9KappgG9uBjxdUnx1nHARWd5LaJH1a0pb89WlJbfmybkk3SdopabukH0oq5csul7RZ0pOSNkh65Tjbv1bSx/Ppl0vql/Q+SY9LelTSxbXWi4ifAJuBN1dsqwm4ELhO0tMlfVfStvzb95clzavo+5Ck/ybpLklPSPo/kk6qrGOS/3z+SdJj+TZuk/SsyawXETuBrwPnVi36FnAQuGiC1a8Dlkl62WTey05sDgI7HnwQeAHZB9Y5wArgQ/my9wH9QA9wKvDnQEg6G7gMOC8i5gCvAR6a5Ps9BZgL9ALvBNZImj9O3y+SHQGUvQpoAW4GBHwCeCrwTGAh8JGq9f8AWAksBpYBfzjJGivdDCwBTgF+Dnx5MitJ6gLeBGysWhTAh4H/LqllnNX3Av8T+B9HUa+dYBwEdjx4K/CXEfF4RAwAHwXeli8bBE4DzoiIwfzcegDDQBuwVFJLRDwUEb+e5PsN5u83GBHrgd3AeOfr/wF4maQF+fzbga/k626MiO9ExIG87k8B1d+gr4qILflppH/h8G/nRxQR10TEkxFxgCxozpE0d4JVrpL0BLAV6Ab+pMY21wEDwB9NsJ3PAadLOn+qNduJxUFgx4OnAg9XzD+ctwF8kuwb7bclPSDpCoCI2Ai8l+yD8XFJN0h6KpOzLSKGKub3kp1LP0xEPALcBlwkqQN4A9lpEySdkr/vZkm7gC+RffBWemwy7zMeSU2S/krSr/P3eChfVP0+ld4dEXPJjkDmAwvG6fchsqOxk2otzIPnY/lLU6nbTiwOAjsebAHOqJg/PW8j/yb8voh4GvB7wJ+WrwVExFci4iX5ugFcWVB915EdCbwZeDAifp63fyJ/32URcTLZOffp/sC8EFhFdkpqLrAobz/i+0TE3WQXfNdIOqx/RHyHLGT/ywSb+UL+vm+cUtV2QnEQ2ExrkXRSxasZuB74kKQeSd3AX5B9u0bS6/JbFwXsIjslNCzpbEmvyC8q7wf25cuK8FWy8/8fJT8ayM0hO620U1Iv8P4C3nsOcADYBswmO28/FdeRXVt4/TjLPwj82Xgr50dOHwEun+L72gnEQWAzbT3Zh3b59RGyb619wF3A3WQXRMu3Li4B/i/ZB+5PgM9GxPfJrg/8Fdl58MfIPuz+vIiCI2IPY2FQeaH2o8DzgCeAbwI3FvD2XyQ7VbYZuA/416msHBEHgavILg7XWv4j4GdH2Mz1wKNTeV87scg/TGNmljYfEZiZJc5BYGaWOAeBmVniHARmZolrrncBU9Xd3R2LFi2qdxlmZieUO+64Y2tE9NRadsIFwaJFi+jr66t3GWZmJxRJD4+3zKeGzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHHJBMGGx57kk7f8kh17Dta7FDOz40oyQfDg1j2s+d6v2bxzX71LMTM7riQTBN0drQBs9xGBmdkhkgmCznYHgZlZLckEQVdHGwBbdx+ocyVmZseXZILg5JOaaWmSjwjMzKokEwSS6GxvZdtuB4GZWaVkggCgs72NbT4iMDM7RFJB0NXeyrY9vkZgZlYprSDoaPU1AjOzKkkFQWd7K9t9jcDM7BBJBUF3RxtPHhjiwNBwvUsxMztuJBUEfqjMzOxwSQVBVx4EvoXUzGxMWkGQjzfkW0jNzMYkFQSd7dkwE9s8zISZ2aikgqDLI5CamR2m0CCQtFLSBkkbJV1RY/lcSf8i6ReS7pV0cZH1zGnLxhva6msEZmajCgsCSU3AGuB8YClwgaSlVd3+GLgvIs4BXg78jaTWAmuiq72N7X662MxsVJFHBCuAjRHxQEQcBG4AVlX1CWCOJAEdwHZgqMCasofKfGrIzGxUkUHQC2yqmO/P2yp9BngmsAW4G3hPRIxUb0jSJZL6JPUNDAwcU1FdHa0+NWRmVqHIIFCNtqiafw1wJ/BU4FzgM5JOPmyliKsjYnlELO/p6Tmmorp8RGBmdogig6AfWFgxv4Dsm3+li4EbI7MReBB4RoE1ZUNR+/ZRM7NRRQbB7cASSYvzC8CrgXVVfR4BXgkg6VTgbOCBAmuiq6OVPQeH2T/o8YbMzKDAIIiIIeAy4BbgfuAfI+JeSZdKujTv9jHgRZLuBm4FLo+IrUXVBBXDTPj0kJkZAM1Fbjwi1gPrq9rWVkxvAX6nyBqqlX/Efvvug/TOmzWTb21mdlxK6sliGBuB1L9UZmaWSS4Iujs8AqmZWaXkgsC/SWBmdqjkgqCjrZnWphJbfWrIzAxIMAgkZT9i71NDZmZAgkEA2ekh3z5qZpZJMgi6OtocBGZmuTSDoL3VQ1GbmeWSDQLfPmpmlkkyCDo7Wtl7cJh9Bz3ekJlZkkHQ5aeLzcxGJRoE+XhDvmBsZpZmEHR2eARSM7OyJIOgfGrID5WZmSUaBB5vyMxsTJJBUB5vyKeGzMwSDQJJdPqhMjMzINEgAPIg8BGBmVmyQdDV4YHnzMyg4CCQtFLSBkkbJV1RY/n7Jd2Zv+6RNCyps8iaynxEYGaWKSwIJDUBa4DzgaXABZKWVvaJiE9GxLkRcS7wAeAHEbG9qJoqdbb7NwnMzKDYI4IVwMaIeCAiDgI3AKsm6H8BcH2B9Ryiq72VJw8McWDI4w2ZWdqKDIJeYFPFfH/edhhJs4GVwFfHWX6JpD5JfQMDA9NSXGc+zMSOPYPTsj0zsxNVkUGgGm0xTt/fA3403mmhiLg6IpZHxPKenp5pKa7TA8+ZmQHFBkE/sLBifgGwZZy+q5nB00Lgp4vNzMqKDILbgSWSFktqJfuwX1fdSdJc4GXANwqs5TAOAjOzTHNRG46IIUmXAbcATcA1EXGvpEvz5Wvzrm8Evh0Re4qqpZbR3yTwnUNmlrjCggAgItYD66va1lbNXwtcW2Qdtcyd1UJTST4iMLPkJftkcakk5s9u8dPFZpa8ZIMA8MBzZmY4CHxqyMySl3QQdLW3+dSQmSUv6SDwEYGZmYOAnXsHGRoeqXcpZmZ1k3QQdHVkzxLs2OvxhswsXUkHgZ8uNjNzEAAeeM7M0pZ0EHTlQ1H7iMDMUpZ0EPjUkJlZ4kEwf3YL4IHnzCxtSQdBc1OJebNbfERgZklLOgjAD5WZmSUfBF3trb5ryMySlnwQdLa3+gfszSxpDgIPPGdmiUs+CLraW9mx9yAjI1HvUszM6iL5IOhsb2V4JNi136eHzCxNyQdBeeA5nx4ys1QVGgSSVkraIGmjpCvG6fNySXdKulfSD4qspxY/XWxmqWsuasOSmoA1wKuBfuB2Sesi4r6KPvOAzwIrI+IRSacUVc94Rgee89PFZpaoIo8IVgAbI+KBiDgI3ACsqupzIXBjRDwCEBGPF1hPTR54zsxSV2QQ9AKbKub787ZKZwHzJX1f0h2S3l5rQ5IukdQnqW9gYGBai5zfXh5vyA+VmVmaigwC1WirvkezGfgt4HeB1wAflnTWYStFXB0RyyNieU9Pz7QW2dbcxJyTmn2x2MySVdg1ArIjgIUV8wuALTX6bI2IPcAeSbcB5wC/KrCuw3R5vCEzS1iRRwS3A0skLZbUCqwG1lX1+QbwUknNkmYDzwfuL7Cmmjo93pCZJaywI4KIGJJ0GXAL0ARcExH3Sro0X742Iu6X9C3gLmAE+HxE3FNUTePp6mhj0/a9M/22ZmbHhSJPDRER64H1VW1rq+Y/CXyyyDqOpKu9lV9s2lnPEszM6ib5J4th7DcJIjzekJmlx0FAFgRDI8GufUP1LsXMbMY5CIDujuyhMl8wNrMUOQjweENmljYHAWNBsNXjDZlZghwEjJ0a8hGBmaXIQcDYeEPbfY3AzBLkICAfb6it2aeGzCxJDoJcZ4fHGzKzNE0qCCS1Syrl02dJer2klmJLm1keeM7MUjXZI4LbgJMk9QK3AhcD1xZVVD10trd5KGozS9Jkg0ARsRd4E/C3EfFGYGlxZc28rvZW/ziNmSVp0kEg6YXAW4Fv5m2FDlg30zo7Wtmx1+MNmVl6JhsE7wU+AHwtH0r6acD3CquqDrraWxkcDnbt93hDZpaWSX2rj4gfAD8AyC8ab42IdxdZ2Ezr6sieLt62+wBzZzXUdXAzswlN9q6hr0g6WVI7cB+wQdL7iy1tZnW2++liM0vTZE8NLY2IXcAbyH5o5nTgbUUVVQ9d+XhDvnPIzFIz2SBoyZ8beAPwjYgYBBrqqmr51JCPCMwsNZMNgs8BDwHtwG2SzgB2FVVUPZRHIPUtpGaWmsleLL4KuKqi6WFJv11MSfXR1txER1uzTw2ZWXIme7F4rqRPSerLX39DdnRwpPVWStogaaOkK2osf7mkJyTdmb/+4ij2Ydp0ebwhM0vQZB8Kuwa4B/iDfP5twBfInjSuSVITsAZ4NdAP3C5pXUTcV9X1hxHxuilVXZDO9la2eQRSM0vMZIPg6RHx5or5j0q68wjrrAA2RsQDAJJuAFaR3X56XOpqb2Xzzv31LsPMbEZN9mLxPkkvKc9IejGw7wjr9AKbKub787ZqL5T0C0k3S3pWrQ1JuqR8WmpgYGCSJU9dV3ubf5zGzJIz2SOCS4EvSpqbz+8A3nGEdVSjrfqW058DZ0TEbkmvBb4OLDlspYirgasBli9fXthtq+XfJIgIpFrlm5k1nkkdEUTELyLiHGAZsCwingu84gir9QMLK+YXAFuqtrsrInbn0+vJnlfonmzx083jDZlZiqb0C2X5B3f5+YE/PUL324ElkhZLagVWA+sqO0h6ivKv3pJW5PVsm0pN06n8LIHvHDKzlBzLUNITnjuJiCFJlwG3AE3ANfnIpZfmy9cCvw+8S9IQ2TWH1VHHcaC7OsrjDR1gcfcR7441M2sIxxIER/zAzk/3rK9qW1sx/RngM8dQw7QqjzfkH7E3s5RMGASSnqT2B76AWYVUVEdjQ1E7CMwsHRMGQUTMmalCjgedo0cEvoXUzNIxpYvFja6tuYl5s1scBGaWFAdBlZ6ONgaedBCYWTocBFV65jgIzCwtDoIq3R1tDPjUkJklxEFQxUcEZpYaB0GVnjlt7D04zJ4DHmbCzNLgIKjSkz9d7DuHzCwVDoIq3XOyIPDpITNLhYOgSvmIwEFgZqlwEFTpKR8R+NSQmSXCQVCls72VkmCrjwjMLBEOgipNJdHZ7mcJzCwdDoIa/CyBmaXEQVCDg8DMUuIgqKGno80/TmNmyXAQ1FA+Iqjjr2aamc0YB0EN3R2tHBweYdc+DzNhZo2v0CCQtFLSBkkbJV0xQb/zJA1L+v0i65mssWcJ9te5EjOz4hUWBJKagDXA+cBS4AJJS8fpdyVwS1G1TFU5CB73BWMzS0CRRwQrgI0R8UBEHARuAFbV6PcnwFeBxwusZUpOmVMeeM4XjM2s8RUZBL3Apor5/rxtlKRe4I3A2ok2JOkSSX2S+gYGBqa90GrdHm/IzBJSZBCoRlv1bTifBi6PiOGJNhQRV0fE8ohY3tPTM131jWvurBZamuQgMLMkNBe47X5gYcX8AmBLVZ/lwA2SALqB10oaioivF1jXEUnyj9ibWTKKDILbgSWSFgObgdXAhZUdImJxeVrStcBN9Q6Bsp45Hm/IzNJQWBBExJCky8juBmoCromIeyVdmi+f8LpAvXV3tPHoE7591MwaX5FHBETEemB9VVvNAIiIPyyylqnqmdPGXZufqHcZZmaF85PF4+iZ08a23QcYHvEwE2bW2BwE4+iZ08ZIwPY9fpbAzBqbg2Ac/u1iM0uFg2Ac3aNPFzsIzKyxOQjG4SMCM0uFg2Ac5YHnfvOkbyE1s8bmIBhHe1szc2e1sGXnvnqXYmZWKAfBBHrnzWLzDgeBmTU2B8EEFsyfxWYfEZhZg3MQTKB3/iz6d+zzbxebWUNzEExgwfzZ7D04zM69g/UuxcysMA6CCfTOmwVAv68TmFkDcxBMYMH8LAg279xb50rMzIrjIJhAOQh8RGBmjcxBMIG5s1roaGt2EJhZQ3MQTEBS9iyBbyE1swbmIDiCBfktpGZmjcpBcAS982exeYcvFptZ43IQHEHvvFns2j/Erv1+lsDMGpOD4AgWzJ8N4DGHzKxhFRoEklZK2iBpo6QraixfJekuSXdK6pP0kiLrORq9voXUzBpcc1EbltQErAFeDfQDt0taFxH3VXS7FVgXESFpGfCPwDOKqulojD5U5usEZtagijwiWAFsjIgHIuIgcAOwqrJDROyOsRHd2oHjbnS3rvZWTmop+RZSM2tYRQZBL7CpYr4/bzuEpDdK+iXwTeA/1dqQpEvyU0d9AwMDhRQ7nvKzBD41ZGaNqsggUI22w77xR8TXIuIZwBuAj9XaUERcHRHLI2J5T0/P9FY5Cb3zZ/uIwMwaVpFB0A8srJhfAGwZr3NE3AY8XVJ3gTUdFT9UZmaNrMgguB1YImmxpFZgNbCusoOkMyUpn34e0ApsK7Cmo9I7bxbb9xxk78GhepdiZjbtCrtrKCKGJF0G3AI0AddExL2SLs2XrwXeDLxd0iCwD3hLHIc/BzZ259A+lpw6p87VmJlNr8KCACAi1gPrq9rWVkxfCVxZZA3TYXQ46p0OAjNrPH6yeBJ65/npYjNrXA6CSThlThutTSUe2e6Hysys8TgIJqFUEmc/ZQ73bdlV71LMzKadg2CSnt07l7v6d3IcXss2MzsmDoJJWrZgLrv2D/n0kJk1HAfBJD2ndy4Ad29+os6VmJlNLwfBJJ116hxam0rc3e8gMLPG4iCYpNbmEs84bY6PCMys4TgIpuA5vXO5e/MTvmBsZg3FQTAFyxbM5cn9Qzy8zReMzaxxOAim4Nn5BeO7fHrIzBqIg2AKzjp1Dq3NJe7u31nvUszMpo2DYApamko887STfcHYzBqKg2CKlvXO5Z7NuxgZ8QVjM2sMDoIpek7vXHYfGOKhbXvqXYqZ2bRwEEzRcxb4CWMzaywOgilackoHbc0l/u2RnfUuxcxsWjgIpqi5qcRLl3Rz012PMjg8Uu9yzMyOmYPgKFz4/NPZuvsA37nvN/UuxczsmDkIjsLLzjqF3nmz+PJPH653KWZmx6zQIJC0UtIGSRslXVFj+Vsl3ZW/fizpnCLrmS5NJbH6vIX8aOM2Htzqu4fM7MRWWBBIagLWAOcDS4ELJC2t6vYg8LKIWAZ8DLi6qHqm21vOW0hTSVz/s0fqXYqZ2TEp8ohgBbAxIh6IiIPADcCqyg4R8eOI2JHP/iuwoMB6ptUpJ5/E7yw9lX/q28T+weF6l2NmdtSKDIJeYFPFfH/eNp53AjfXWiDpEkl9kvoGBgamscRjc+HzT2fH3kFuufexepdiZnbUigwC1WirOS6DpN8mC4LLay2PiKsjYnlELO/p6ZnGEo/Ni5/ezeLudq68+Zds2bmv3uWYmR2VIoOgH1hYMb8A2FLdSdIy4PPAqojYVmA9065UEn97wXN5cv8QF/39T9m2+0C9SzIzm7Iig+B2YImkxZJagdXAusoOkk4HbgTeFhG/KrCWwjy7dy7XXHweW3bu4x1f+Bm79g/WuyQzsylpLmrDETEk6TLgFqAJuCYi7pV0ab58LfAXQBfwWUkAQxGxvKiainLeok7+7qLf4j9f18eLP/FdTu+azYL5s+jqaKO1qURLk2hpKtHSVKK1OZtvLpVoaS7RUhLNFX2aS/nfcp+mbHlzSaNth0w3ieaSaCodOp//8zQzOyKdaL+/u3z58ujr66t3GTX9eONWbr7nMfp37GXTjn3s2HOQweERBoeDg8MjDM/g0NUlQXOplAeEaMoDoqT8b+nQv02lEk0lsr/KnpUov0rKp5X1b8rns2koVbSXSqKplLepvG52Gq2kvI/G5g+bVhZipYrtjk6LfFll38r3AuV9RHl9EGP9Rv/C6PuoYl04fNvAIeuLQ/tnbYe+bzmHK+spr1vuT9V8dT/K+1NjWWXOH7bdiv7l5eU2S5ekO8b7ol3YEUGKXnRmNy86s3vc5RExGgpDeUAMDo8wNBwMjoyMTQ+PMDQytmxopPw3axseyaaHhoPhkZHR6aGRbH5wOBiJcp8RhkfI2keCkZFgOH8NjQTDEQzn647E2LLhfNngYPZ+EeXtj/UbCcamy9sayfZzOG+PYHRbEdk6MxmIVlutgIE8gEY7cUiYlJeN9T00XFRjPSr6aLz2im0e8uYV7314a3W7Dqmr+j0mUh2qldus1V79Hoduq8Y/j8M6Hbl5vLpXn7eQP3rp08bb8lFzEMwgSbQ2i9Zmj+wRERUBQRYYkYVMjGQBM5IHRzlYIg+ekREIKkNlbDoiW1beZnk7kb/nSFU7wWiglfuUtzEyUtmeL2Ns/XJ/yssp1zjWl8p6qvpFvmKt7Y+37fLybNMxNh0V01V9qNhmeaa6lvJ6FV1G16Vi3UNrOrR/dU3V/74n279Wv+olle2VtR7SfngZNfrUXuHQGg7d0uS2O16f2kvG2c3DdHe0jb/wGDgIrC6k/DpHvQsxMw86Z2aWOgeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJe6EG2tI0gBwtL8a3w1sncZyThQp7neK+wxp7neK+wxT3+8zIqLmD7qccEFwLCT1nYijmx6rFPc7xX2GNPc7xX2G6d1vnxoyM0ucg8DMLHGpBcHV9S6gTlLc7xT3GdLc7xT3GaZxv5O6RmBmZodL7YjAzMyqOAjMzBKXTBBIWilpg6SNkq6odz1FkLRQ0vck3S/pXknvyds7JX1H0r/nf+fXu9bpJqlJ0r9JuimfT2Gf50n6Z0m/zP+dvzCR/f6v+X/f90i6XtJJjbbfkq6R9Likeyraxt1HSR/IP9s2SHrNVN8viSCQ1ASsAc4HlgIXSFpa36oKMQS8LyKeCbwA+ON8P68Abo2IJcCt+XyjeQ9wf8V8Cvv8v4BvRcQzgHPI9r+h91tSL/BuYHlEPBtoAlbTePt9LbCyqq3mPub/j68GnpWv89n8M2/SkggCYAWwMSIeiIiDwA3AqjrXNO0i4tGI+Hk+/STZB0Mv2b5el3e7DnhDXQosiKQFwO8Cn69obvR9Phn4D8DfA0TEwYjYSYPvd64ZmCWpGZgNbKHB9jsibgO2VzWPt4+rgBsi4kBEPAhsJPvMm7RUgqAX2FQx35+3NSxJi4DnAj8FTo2IRyELC+CUOpZWhE8DfwaMVLQ1+j4/DRgAvpCfEvu8pHYafL8jYjPw18AjwKPAExHxbRp8v3Pj7eMxf76lEgSq0daw981K6gC+Crw3InbVu54iSXod8HhE3FHvWmZYM/A84O8i4rnAHk780yFHlJ8XXwUsBp4KtEu6qL5V1d0xf76lEgT9wMKK+QVkh5MNR1ILWQh8OSJuzJt/I+m0fPlpwOP1qq8ALwZeL+khslN+r5D0JRp7nyH7b7o/In6az/8zWTA0+n6/CngwIgYiYhC4EXgRjb/fMP4+HvPnWypBcDuwRNJiSa1kF1bW1bmmaSdJZOeM74+IT1UsWge8I59+B/CNma6tKBHxgYhYEBGLyP69fjciLqKB9xkgIh4DNkk6O296JXAfDb7fZKeEXiBpdv7f+yvJroU1+n7D+Pu4DlgtqU3SYmAJ8LMpbTkikngBrwV+Bfwa+GC96yloH19Cdkh4F3Bn/not0EV2l8G/5387611rQfv/cuCmfLrh9xk4F+jL/31/HZifyH5/FPglcA/wD0Bbo+03cD3ZNZBBsm/875xoH4EP5p9tG4Dzp/p+HmLCzCxxqZwaMjOzcTgIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzKpIGpZ0Z8Vr2p7YlbSockRJs+NBc70LMDsO7YuIc+tdhNlM8RGB2SRJekjSlZJ+lr/OzNvPkHSrpLvyv6fn7adK+pqkX+SvF+WbapL0v/Mx9b8taVbddsoMB4FZLbOqTg29pWLZrohYAXyGbNRT8ukvRsQy4MvAVXn7VcAPIuIcsnGA7s3blwBrIuJZwE7gzYXujdkR+MlisyqSdkdER432h4BXRMQD+eB+j0VEl6StwGkRMZi3PxoR3ZIGgAURcaBiG4uA70T24yJIuhxoiYiPz8CumdXkIwKzqYlxpsfrU8uBiulhfK3O6sxBYDY1b6n4+5N8+sdkI58CvBX4f/n0rcC7YPQ3lU+eqSLNpsLfRMwON0vSnRXz34qI8i2kbZJ+SvYl6oK87d3ANZLeT/arYRfn7e8Brpb0TrJv/u8iG1HS7LjiawRmk5RfI1geEVvrXYvZdPKpITOzxPmIwMwscT4iMDNLnIPAzCxxDgIzs8Q5CMzMEucgMDNL3P8Hjaj0tyFaU8AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "#vanilla structure normal\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,num_layers, transform_function='relu'):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.transform_function = transform_function\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        out, hidden = self.rnn(inputs, hidden)\n",
    "        out = F.relu(out) #apply transformation function\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function='relu'):\n",
    "    \n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0] \n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out,num_layers=1, transform_function=transform_function)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "    \n",
    "    return rnn_model\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------parameters-------------\n",
    "#----------------------------------------\n",
    "\n",
    "#input weight matrix\n",
    "W_in = torch.eye(2)\n",
    "print('W_inn=',W_in.shape)\n",
    "\n",
    "#recurrent weight matrix\n",
    "W_hh = torch.eye(2)\n",
    "print('W_hh=',W_hh.shape)\n",
    "\n",
    "#output weitght matrix\n",
    "W_out = torch.Tensor(np.array([[-1,1]]))\n",
    "print('w_out=',W_out.shape)\n",
    "\n",
    "#recurrent bias\n",
    "b_hh = torch.Tensor(np.array([[0,0]]))\n",
    "print('b_hh=',b_hh.shape)\n",
    "\n",
    "#output bias\n",
    "b_out = torch.Tensor([0])\n",
    "print('b_out=',b_out.shape)\n",
    "\n",
    "rnn_model = make_rnn_from_networkparameters(W_in,W_hh,W_out,b_hh,b_out)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "#input_sequence = torch.Tensor([[1, 0], [0, 1], [1, 1]])  \n",
    "input_size = 2\n",
    "input_length = 3\n",
    "batch_size= 1\n",
    "output_size = 1\n",
    "input_sequence = torch.randn(batch_size, input_length, input_size)\n",
    "print('Input Sequence = ',input_sequence)\n",
    "\n",
    "#inicialize the hidden state\n",
    "hidden_state = rnn_model.init_hidden(input_sequence.size(0)) \n",
    "print('hidden state = ',hidden_state)\n",
    "\n",
    "target_output = torch.randn(batch_size,input_length,output_size)\n",
    "print('Target = ',target_output)\n",
    "\n",
    "num_epochs = 100\n",
    "#----------------------------------------\n",
    "# ----------------train-------------------\n",
    "#----------------------------------------\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, hidden = rnn_model(input_sequence, hidden_state)\n",
    "    loss = criterion(outputs, target_output)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_vector.append(loss.item())\n",
    "    # Print the training loss for every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------test-------------------\n",
    "#----------------------------------------\n",
    "#evaluation mode\n",
    "rnn_model.eval()\n",
    "\n",
    "#forward pass on test input\n",
    "test_outputs, _ = rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0)))\n",
    "\n",
    "# Print the test outputs\n",
    "print(\"Test Outputs:\")\n",
    "print(test_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c01eea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\ASUS\\\\F.Champalimaud',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\python39.zip',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd8832",
   "metadata": {},
   "source": [
    "## --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b44023",
   "metadata": {},
   "source": [
    "### other experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f3070",
   "metadata": {},
   "source": [
    "## ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d05fda",
   "metadata": {},
   "source": [
    "Define the ODE function:\n",
    "$\\dot{x}=-x+\\left [ Wx+b \\right ]_{+}$\n",
    "Where x is the hidden state, b is the bias, and $\\left [ \\cdot  \\right ]_{+}=max(0,\\cdot )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a201979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3997265   0.58227564  1.09807511  0.78365554 -0.48180916]\n",
      "Integrated output: [ 0.14706616  0.86011094  0.45784723  0.28832017 -0.17726577]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "#define the ODE function\n",
    "def ode_func(t, state, w, b):\n",
    "    wx_plus_b = np.maximum(0, np.dot(w, state) + b)\n",
    "    dstate_dt = -state + wx_plus_b\n",
    "    return dstate_dt\n",
    "\n",
    "#integration function\n",
    "def integrate_rnn_attractors(w, b, initial_state, t_start, t_end, num_points):\n",
    "    t_span = (t_start, t_end)\n",
    "    t_eval = np.linspace(t_start, t_end, num_points)\n",
    "\n",
    "    ode_args = (w, b)\n",
    "    solution = solve_ivp(ode_func, t_span, initial_state, t_eval=t_eval, args=ode_args)\n",
    "\n",
    "    return solution.t, solution.y\n",
    "\n",
    "#define parameters and initial conditions\n",
    "num_units = 5\n",
    "w = np.random.randn(num_units, num_units)  # Connectivity matrix\n",
    "#b = np.random.randn(num_units)  # Bias vector\n",
    "initial_state = np.random.randn(num_units)\n",
    "#initial_state = torch.randint(2, size=(1,num_units)).float()\n",
    "print(initial_state)\n",
    "\n",
    "#print(lele)\n",
    "t_start = 0\n",
    "t_end = 1\n",
    "num_points = 1000\n",
    "\n",
    "#integration\n",
    "t, state = integrate_rnn_attractors(w, b, initial_state, t_start, t_end, num_points)\n",
    "\n",
    "#result\n",
    "integrated_output = state[:, -1]\n",
    "print(\"Integrated output:\", integrated_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1529e3",
   "metadata": {},
   "source": [
    "for **unbounded line attractors (BLA)**, the W = $\\begin{bmatrix}\n",
    "0 & 1\\\\ 1 & 0\n",
    "\\end{bmatrix}$\n",
    "and b= 0. \n",
    "\n",
    "The resulting flow diverges to infinity along the diagonal. The backpropagating over time exponentially grows in magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f017cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated output: [0. 0.]\n",
      "Integrated output: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def ode_func(t, state, b):\n",
    "    w = np.array([[0, 1], [1, 0]])\n",
    "    wx_plus_b = np.maximum(0, np.dot(w, state) + b)\n",
    "    dstate_dt = -state + wx_plus_b\n",
    "    return dstate_dt\n",
    "\n",
    "def integrate_rnn_attractors(b, initial_state, t_start, t_end, num_points):\n",
    "    t_span = (t_start, t_end)\n",
    "    t_eval = np.linspace(t_start, t_end, num_points)\n",
    "\n",
    "    ode_args = (b,)\n",
    "    solution = solve_ivp(ode_func, t_span, initial_state, t_eval=t_eval, args=ode_args)\n",
    "\n",
    "    return solution.t, solution.y\n",
    "\n",
    "num_units = 2\n",
    "b = 0  # Bias vector\n",
    "initial_state = np.zeros(num_units)\n",
    "t_start = 0\n",
    "t_end = 1\n",
    "num_points = 1000\n",
    "\n",
    "t, state = integrate_rnn_attractors(b, initial_state, t_start, t_end, num_points)\n",
    "\n",
    "integrated_output = state[:, -1]\n",
    "print(\"Integrated output:\", integrated_output)\n",
    "\n",
    "integrated_output = state[:, -1]\n",
    "print(\"Integrated output:\", integrated_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceba224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_input is the input sequence for testing\n",
    "test_input = test_input = torch.randn(sequence_length, input_size)  # Test input sequence\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    test_input = torch.tensor(test_input, dtype=torch.float32)\n",
    "    predicted_output = model(test_input.unsqueeze(0).unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "    print(\"Predicted output:\", predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c45a7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Trial: tensor([0.])\n",
      "Target: tensor([[0.9264]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7572\\955524387.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype=torch.float32).unsqueeze(0)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7572\\955524387.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 60>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(inputs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     66\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(targets, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     71\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mAttractorLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Pass through LSTM\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Apply ReLU and linear layer\u001b[39;00m\n\u001b[0;32m     47\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:803\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    801\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 2-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 803\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    804\u001b[0m         hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# number of trials and sequence length\n",
    "num_trials = 1000\n",
    "sequence_length = 1\n",
    "input_size = 1\n",
    "\n",
    "# Random sequence of 0 and 1\n",
    "input_trials = torch.randint(2, size=(num_trials, sequence_length)).float()\n",
    "\n",
    "# Generation of random input trials\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    # Cumulative sum of the sequence\n",
    "    target = torch.cumsum(sequence, dim=0)\n",
    "    targets.append(target)\n",
    "\n",
    "# Convert input trials and targets to tensors\n",
    "target_trials = torch.stack(targets).float()\n",
    "\n",
    "sample_index = 0\n",
    "print(\"Input Trial:\", input_trials[sample_index])\n",
    "print(\"Target:\", targets[sample_index])\n",
    "\n",
    "class AttractorLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(AttractorLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # get the batch size\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Apply ReLU and linear layer\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(2)\n",
    "\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "\n",
    "model = AttractorLSTM(input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for inputs, targets in zip(input_trials, target_trials):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).unsqueeze(0)\n",
    "        targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(input_trials)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22279276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
