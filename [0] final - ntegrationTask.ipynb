{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66809092",
   "metadata": {},
   "source": [
    "## RNN Integration Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b061868",
   "metadata": {},
   "source": [
    "Integration task in **recurrent neural network** with:\n",
    "- a reLU function\n",
    "- backpropagating method\n",
    "- MSE error\n",
    "- LSTM architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186f9502",
   "metadata": {},
   "source": [
    "implement input trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc08255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Trial: tensor([1., 0.])\n",
      "Target: tensor([[ 0.6852, -0.6041],\n",
      "        [ 0.0495, -1.4055]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#number of trials and sequence length\n",
    "num_trials = 100\n",
    "sequence_length = 2\n",
    "#Random sequence of 0 and 1\n",
    "input_trials = torch.randint(2, size=(num_trials, sequence_length)).float()\n",
    "\n",
    "#Generation of random input trials\n",
    "#input_trials = []\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    #Cumulative sum of the sequenced\n",
    "    target = torch.cumsum(sequence, dim=0)\n",
    "    #add the sequence and target to the input trials\n",
    "    targets.append(target)\n",
    "\n",
    "#Convert input trials and targets to tensors\n",
    "targets = torch.stack(targets).float()\n",
    "\n",
    "sample_index = 0\n",
    "print(\"Input Trial:\", input_trials[sample_index])\n",
    "print(\"Target:\", targets[sample_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d7cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([100, 2, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Input: tensor([[ 0.1210, -0.4106],\n",
      "        [-0.4351,  0.6871]])\n",
      "Predicted Output: tensor([0.0398, 0.0124])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "#LSTM-based integration model\n",
    "class IntegrationModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(IntegrationModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "       \n",
    "    def forward(self, input_seq):\n",
    "        _, (hidden, _) = self.lstm(input_seq)\n",
    "        output = self.fc(self.relu(hidden[-1]))\n",
    "        return output\n",
    " \n",
    "\n",
    "\n",
    "    \n",
    "input_size = 2  #size of the input sequence\n",
    "hidden_size = 32  #nr of hidden units in the LSTM layer\n",
    "output_size = 2  #size of the output (predicted integrated value)\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "model = IntegrationModel(input_size, hidden_size, output_size)\n",
    "\n",
    "#loss function and the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#adam optimizer adjust the learning rate based on the momentum of the gradient\n",
    "#can accelarate the gradient descent, no guarantee to converge\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=learning_rate) #????\n",
    "\n",
    "x_axis = torch.arange(0,num_epochs)\n",
    "loss_vector_adam = []\n",
    "#print(outputs)\n",
    "#----------------------------------\n",
    "#Training loop with adam optimizer\n",
    "#----------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    #forward pass\n",
    "    outputs = model(input_trials)\n",
    "    #print('outputs = ',outputs)\n",
    "\n",
    "    optimizer_adam.zero_grad()#set the gradients to zero\n",
    "    #loss calculous\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    #Backpropagation and optimization\n",
    "    loss.backward() #backpropagating\n",
    "    optimizer_adam.step() #parameter update\n",
    "    \n",
    "    loss_vector_adam.append(loss.item())\n",
    "    #tracking training progress\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "loss_vector_sgd = []\n",
    "#using a regular stochastic gradient descent\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "#----------------------------------\n",
    "#Training loop with regular stochastic gradient descent\n",
    "#----------------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    #forward pass\n",
    "    outputs = model(input_trials)\n",
    "\n",
    "    optimizer_sgd.zero_grad()#set the gradients to zero\n",
    "    #loss calculous\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    #Backpropagation and optimization\n",
    "    loss.backward() #backpropagating\n",
    "    optimizer_sgd.step() #parameter update\n",
    "    \n",
    "    loss_vector_sgd.append(loss.item())\n",
    "    #tracking training progress\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector_adam,label='Adam Optimizer')\n",
    "plt.plot(x_axis,loss_vector_sgd,label='regular stochastic gradient descent')\n",
    "plt.title('Comparison between Adam Optimizer & regular stochastic gradient descent')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#test the  model\n",
    "model.eval()\n",
    "test_input = torch.randn(sequence_length, input_size) #random input\n",
    "with torch.no_grad(): #temporarily disable gradient computation\n",
    "    predicted_output = model(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", predicted_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1825672e",
   "metadata": {},
   "source": [
    "# ___________22/06 __________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed23828",
   "metadata": {},
   "source": [
    "## Using Vanilla architecture with a single layer and ReLU activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be835678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([100, 1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "Test Input: tensor([[0.2893]])\n",
      "Predicted Output: tensor([0.0795])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#-------------------------------------------------\n",
    "#--------- 22/06 - updated version ---------------\n",
    "#-------------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define Vanilla RNN model\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs, _ = self.rnn(inputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        #print(outputs[ -1,:])\n",
    "        logits = self.fc(outputs[-1,:])  # Take the last output of the sequence\n",
    "        output = torch.relu(logits)\n",
    "        return logits\n",
    "\n",
    "\n",
    "# Define the training data\n",
    "num_trials = 100\n",
    "sequence_length = 1\n",
    "input_size = 1\n",
    "input_trials = torch.randint(2, size=(num_trials, sequence_length)).float()\n",
    "#print('input_trials=',input_trials)\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    #print('sequence=',sequence)\n",
    "    target = torch.cumsum(sequence, dim=0)[-1] #turns positive\n",
    "    \n",
    "    targets.append(target)\n",
    "    #print('targer=',targets)\n",
    "targets = torch.stack(targets).unsqueeze(1).float()\n",
    "#print('targets=',targets)\n",
    "# Hyperparameters\n",
    "hidden_size = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the Vanilla RNN model\n",
    "model = VanillaRNN(input_size, hidden_size)\n",
    "#print('model=',model(input_trials))\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "x_axis = torch.arange(0,num_epochs)\n",
    "loss_vector = []\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    logits = model(input_trials)\n",
    "    #print('logits=',logits)\n",
    "    #print('targets=',targets)\n",
    "    loss = criterion(logits, targets)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vector.append(loss.item())\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector)\n",
    "plt.title('Loss in vanilla RNN')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "#set the initial state\n",
    "batch_size = num_trials\n",
    "initial_hidden = torch.zeros(1, batch_size, hidden_size)\n",
    "print(initial_hidden)\n",
    "\n",
    "\n",
    "#test the  model\n",
    "model.eval()\n",
    "test_input = torch.randn(sequence_length, input_size) #random input\n",
    "\n",
    "with torch.no_grad(): #temporarily disable gradient computation\n",
    "    predicted_output = model(test_input)\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e09f7",
   "metadata": {},
   "source": [
    "## predefined Vanilla RNNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aea9f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaRNN(\n",
      "  (rnn): RNN(3, 2)\n",
      "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (transform): ReLU()\n",
      ")\n",
      "tensor([[0.7840]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.all_weights[0][0][:] = torch.tensor(W_in, dtype=torch.float)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.all_weights[0][1][:] = torch.tensor(W_hh, dtype=torch.float)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.all_weights[0][2][:] =  torch.tensor(b_hh, dtype=torch.float)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_3748\\2339530310.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.transform = transform_function\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.transform(outputs)  # Apply the transform function\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function=nn.ReLU()):\n",
    "    \"\"\"\n",
    "    Input, recurrent and output weight and recurrent and output biases need to be given\n",
    "    Returns PyTorch RNN with given weights.\n",
    "    \"\"\"\n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0]\n",
    "\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function)\n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.all_weights[0][0][:] = torch.tensor(W_in, dtype=torch.float)\n",
    "        rnn_model.rnn.all_weights[0][1][:] = torch.tensor(W_hh, dtype=torch.float)\n",
    "        rnn_model.rnn.all_weights[0][2][:] =  torch.tensor(b_hh, dtype=torch.float)\n",
    "        rnn_model.rnn.all_weights[0][3][:] =  torch.zeros((N_rec), dtype=torch.float)\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Define the network parameters as PyTorch tensors\n",
    "W_in = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]], dtype=torch.float)  # Input weights\n",
    "W_hh = torch.tensor([[0.7, 0.8], [0.9, 1.0]], dtype=torch.float)  # Recurrent weights\n",
    "W_out = torch.tensor([[0.2, 0.4]], dtype=torch.float)  # Output weights\n",
    "b_hh = torch.tensor([0.1, 0.2], dtype=torch.float)  # Recurrent biases\n",
    "b_out = torch.tensor([0.3], dtype=torch.float)  # Output biases\n",
    "\n",
    "# Create an RNN model using the network parameters and ReLU as the transform function\n",
    "rnn_model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, nn.ReLU())\n",
    "\n",
    "# Print the model architecture\n",
    "print(rnn_model)\n",
    "\n",
    "# Perform forward pass with sample input\n",
    "input_data = torch.tensor([[[0.2, 0.4, 0.6], [0.3, 0.5, 0.7]]], dtype=torch.float)  # Sample input\n",
    "output, _ = rnn_model(input_data)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c7f6e",
   "metadata": {},
   "source": [
    "### Vanilla RNN with initializing the hidden state and linear in ReLU function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "838645fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_trials= tensor([[[1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [1., 1.],\n",
      "         [0., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.],\n",
      "         [0., 1.],\n",
      "         [0., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 1.],\n",
      "         [1., 0.],\n",
      "         [1., 1.],\n",
      "         [1., 0.]]])\n",
      "Test Input: tensor([[ 0.1095,  0.7589],\n",
      "        [-0.0199,  0.8991]])\n",
      "Predicted Output: (tensor([[-0.1305]]), tensor([[[0.1388, 0.0000, 0.0522, 0.2466, 0.0725, 0.1578, 0.1119, 0.0000,\n",
      "          0.0000, 0.0000, 0.0899, 0.0248, 0.0000, 0.1823, 0.0000, 0.1904,\n",
      "          0.0687, 0.0000, 0.0344, 0.2508, 0.0423, 0.3811, 0.0000, 0.0000,\n",
      "          0.0000, 0.0307, 0.0508, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.1741, 0.0000, 0.0735, 0.2546, 0.0686, 0.1556, 0.1468, 0.0000,\n",
      "          0.0000, 0.0000, 0.0991, 0.0247, 0.0000, 0.2013, 0.0000, 0.1808,\n",
      "          0.0647, 0.0000, 0.0608, 0.2597, 0.0309, 0.3727, 0.0000, 0.0000,\n",
      "          0.0000, 0.0249, 0.0565, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([100, 2, 1])) that is different to the input size (torch.Size([2, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size,num_layers = 1,nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.relu(outputs)\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "\n",
    "#training data\n",
    "num_trials = 100\n",
    "sequence_length = 2\n",
    "input_size = 2\n",
    "input_trials = torch.randint(2, size=(sequence_length, batch_size, input_size)).float()\n",
    "#print('input_trials = ', input_trials)\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    target = torch.cumsum(sequence, dim=0)[-1]\n",
    "    targets.append(target)\n",
    "targets = torch.stack(targets).unsqueeze(2).float()\n",
    "#print('targets= ',targets)\n",
    "\n",
    "#Hyperparameters\n",
    "hidden_size = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "#create the Vanilla RNN model\n",
    "model = VanillaRNN(input_size, hidden_size)\n",
    "\n",
    "#loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "print('input_trials=',input_trials)\n",
    "x_axis = torch.arange(0,num_epochs)\n",
    "loss_vector = []\n",
    "#training loop\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    hidden = None\n",
    "    logits, hidden = model(input_trials, hidden)\n",
    "    \n",
    "    \n",
    "    loss = criterion(logits, targets)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vector.append(loss.item())\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    #print(\"Epoch {}: Loss = {}\".format(epoch+1, epoch_loss))\n",
    "    \n",
    "#print loss function\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector)\n",
    "plt.title('Loss in vanilla RNN')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "#set the initial state\n",
    "batch_size = num_trials\n",
    "initial_hidden = torch.zeros(1, batch_size, hidden_size)\n",
    "\n",
    "#test the  model\n",
    "model.eval()\n",
    "test_input = torch.randn(sequence_length, input_size) #random input\n",
    "with torch.no_grad():\n",
    "    predicted_output = model(test_input.unsqueeze(1).transpose(0, 1))\n",
    "\n",
    "print(\"Test Input:\", test_input)\n",
    "print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4437a91b",
   "metadata": {},
   "source": [
    "# 23/06 - updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "229115bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_in= 10 - número de colunas do input\n",
      "N_out= 5 - número de linhas do output\n",
      "N_rec= 20 - número de linhas da camada recurrente\n",
      "Epoch 1/10, Average Loss: 73.19563674926758\n",
      "Epoch 2/10, Average Loss: 6.254050374031067\n",
      "Epoch 3/10, Average Loss: 0.3530493453145027\n",
      "Epoch 4/10, Average Loss: 0.031887530349195004\n",
      "Epoch 5/10, Average Loss: 0.003071403072681278\n",
      "Epoch 6/10, Average Loss: 0.0003072424078709446\n",
      "Epoch 7/10, Average Loss: 2.9642592153322767e-05\n",
      "Epoch 8/10, Average Loss: 3.0416988465731265e-06\n",
      "Epoch 9/10, Average Loss: 2.88157782080134e-07\n",
      "Epoch 10/10, Average Loss: 3.0614388801808445e-08\n",
      "Testing Loss: 23.038602471351624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_8024\\1148653543.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.transform = transform_function\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.transform(outputs)  # Apply the transform function\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "#initializes its weights and biases based on the provided parameters\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function=nn.ReLU()):\n",
    "    \"\"\"\n",
    "    Input, recurrent and output weight and recurrent and output biases need to be given\n",
    "    Returns PyTorch RNN with given weights.\n",
    "    \"\"\"\n",
    "    N_in = W_in.shape[1]\n",
    "    print('N_in=',N_in,'- número de colunas do input')\n",
    "    N_out = W_out.shape[0]\n",
    "    print('N_out=',N_out,'- número de linhas do output')\n",
    "    N_rec = W_hh.shape[0]\n",
    "    print('N_rec=',N_rec,'- número de linhas da camada recurrente')\n",
    "\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function)\n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_hh_l0 = nn.Parameter(torch.zeros((N_rec), dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Initialize the model with desired weights and biases\n",
    "input_size = 10\n",
    "hidden_size = 20\n",
    "output_size = 5\n",
    "\n",
    "W_in = torch.randn(hidden_size, input_size)\n",
    "W_hh = torch.randn(hidden_size, hidden_size)\n",
    "W_out = torch.randn(output_size, hidden_size)\n",
    "b_hh = torch.randn(hidden_size)\n",
    "b_out = torch.randn(output_size)\n",
    "\n",
    "model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out)\n",
    "\n",
    "# Define the training and testing datasets (example)\n",
    "train_dataset = [(torch.randn(1, 1, input_size), torch.tensor([1, 0, 0, 0, 0], dtype=torch.float32)),\n",
    "                 (torch.randn(1, 1, input_size), torch.tensor([0, 1, 0, 0, 0], dtype=torch.float32))]\n",
    "\n",
    "test_dataset = [(torch.randn(1, 1, input_size), torch.tensor([1, 0, 0, 0, 0], dtype=torch.float32)),\n",
    "                (torch.randn(1, 1, input_size), torch.tensor([0, 1, 0, 0, 0], dtype=torch.float32))]\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "\n",
    "x_axis = torch.arange(0,len(train_dataset)*num_epochs)\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for inputs, targets in train_dataset:\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs, _ = model(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        loss_vector.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "# Testing\n",
    "total_loss = 0\n",
    "\n",
    "for inputs, targets in test_dataset:\n",
    "    # Forward pass\n",
    "    outputs, _ = model(inputs)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs.squeeze(), targets)\n",
    "    \n",
    "    total_loss += loss.item()\n",
    "\n",
    "avg_loss = total_loss / len(test_dataset)\n",
    "print(f\"Testing Loss: {avg_loss}\")\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_axis,loss_vector)\n",
    "plt.title('Loss in vanilla RNN')\n",
    "plt.xlabel(\"num_epochs\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f527da8d",
   "metadata": {},
   "source": [
    "## USING THE PARAMETERS IN THE MANUSCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24ebfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_in= 2 - número de colunas do input\n",
      "N_out= 2 - número de linhas do output\n",
      "N_rec= 2 - número de linhas da camada recurrente\n",
      "VanillaRNN(\n",
      "  (rnn): RNN(2, 2)\n",
      "  (fc): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (transform): ReLU()\n",
      ")\n",
      "input_sequence =  tensor([[[-0.4976,  1.1204]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\3924264598.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1, 2].  Tensor sizes: [2, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 74>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     77\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 78\u001b[0m output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target_output)\n\u001b[0;32m     80\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mVanillaRNN.forward\u001b[1;34m(self, inputs, hidden)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 14\u001b[0m     outputs, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(outputs)  \u001b[38;5;66;03m# Apply the transform function\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(outputs[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:513\u001b[0m, in \u001b[0;36mRNN.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    509\u001b[0m         result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mrnn_tanh(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    510\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m    511\u001b[0m                               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 513\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn_relu\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (2) at non-singleton dimension 0.  Target sizes: [1, 2].  Tensor sizes: [2, 1]"
     ]
    }
   ],
   "source": [
    "#-------------isnt running!!!!!!!!!!-----------------\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1, nonlinearity='relu')\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.transform = transform_function\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        outputs, hidden = self.rnn(inputs, hidden)\n",
    "        outputs = self.transform(outputs)  # Apply the transform function\n",
    "        logits = self.fc(outputs[:, -1, :])\n",
    "        return logits, hidden\n",
    "\n",
    "#initializes its weights and biases based on the provided parameters\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function=nn.ReLU()):\n",
    "    \"\"\"\n",
    "    Input, recurrent and output weight and recurrent and output biases need to be given\n",
    "    Returns PyTorch RNN with given weights.\n",
    "    \"\"\"\n",
    "    N_in = W_in.shape[1]\n",
    "    print('N_in=',N_in,'- número de colunas do input')\n",
    "    N_out = W_out.shape[0]\n",
    "    print('N_out=',N_out,'- número de linhas do output')\n",
    "    N_rec = W_hh.shape[0]\n",
    "    print('N_rec=',N_rec,'- número de linhas da camada recurrente')\n",
    "\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function)\n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_hh_l0 = nn.Parameter(torch.zeros((N_rec), dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Initialize the model with desired weights and biases\n",
    "input_size = 2\n",
    "hidden_size = 2\n",
    "output_size = 2\n",
    "\n",
    "# IDENTITY RNN\n",
    "W_in = torch.eye(input_size)\n",
    "W_hh = torch.eye(hidden_size)\n",
    "W_out = torch.Tensor(np.array([[-1],[1]]))\n",
    "b_hh = torch.Tensor(np.array([[0],[0]]))\n",
    "b_out = 0\n",
    "\n",
    "model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Generate a single training sample\n",
    "batch_size = 1\n",
    "input_length = 1\n",
    "input_sequence = torch.randn(batch_size, input_length, input_size)\n",
    "print('input_sequence = ',input_sequence)\n",
    "target_output = torch.tensor([[1,0]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output, _ = model(input_sequence)\n",
    "    loss = criterion(output, target_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_vector.append(loss.item())\n",
    "\n",
    "    # Print the loss for monitoring\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2ab0d3",
   "metadata": {},
   "source": [
    "# 26/06 monday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb8a0c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_inn= torch.Size([2, 2])\n",
      "W_hh= torch.Size([2, 2])\n",
      "w_out= torch.Size([1, 2])\n",
      "b_hh= torch.Size([1, 2])\n",
      "b_out= torch.Size([1])\n",
      "Input Sequence =  tensor([[[-0.7798,  1.1448],\n",
      "         [-0.0938, -2.6223],\n",
      "         [-0.9053,  0.1386]]])\n",
      "hidden state =  tensor([[0., 0.]])\n",
      "Target =  tensor([[[ 0.8834],\n",
      "         [-0.8708],\n",
      "         [ 0.1221]]])\n",
      "Epoch: 1, Loss: 1.085811972618103\n",
      "Epoch: 2, Loss: 0.9576928019523621\n",
      "Epoch: 3, Loss: 0.8473827242851257\n",
      "Epoch: 4, Loss: 0.7517366409301758\n",
      "Epoch: 5, Loss: 0.6683130860328674\n",
      "Epoch: 6, Loss: 0.5951871275901794\n",
      "Epoch: 7, Loss: 0.5308206677436829\n",
      "Epoch: 8, Loss: 0.47396770119667053\n",
      "Epoch: 9, Loss: 0.4236074388027191\n",
      "Epoch: 10, Loss: 0.4126988649368286\n",
      "Test Outputs:\n",
      "tensor([[[1.3129],\n",
      "         [0.0212],\n",
      "         [0.3958]]], grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_in.weight = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.weight = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.bias = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([1, 3, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_in.weight = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.weight = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_hh.bias = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_20344\\1508276578.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc_out.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "#vanilla structure normal\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, transform_function='relu'):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.transform_function = transform_function\n",
    "        self.fc_in = nn.Linear(input_size, hidden_size)\n",
    "        self.fc_hh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        activation = F.relu\n",
    "        hidden = activation(self.fc_in(input) + self.fc_hh(hidden))\n",
    "        output = self.fc_out(hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function='relu'):\n",
    "    \n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0]\n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out, transform_function=transform_function)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rnn_model.fc_in.weight = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.fc_hh.weight = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.fc_hh.bias = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.fc_out.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc_out.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "\n",
    "    return rnn_model\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------parameters-------------\n",
    "#----------------------------------------\n",
    "\n",
    "#input weight matrix\n",
    "W_in = torch.eye(2)\n",
    "print('W_inn=',W_in.shape)\n",
    "\n",
    "#recurrent weight matrix\n",
    "W_hh = torch.eye(2)\n",
    "print('W_hh=',W_hh.shape)\n",
    "\n",
    "#output weitght matrix\n",
    "W_out = torch.Tensor(np.array([[-1,1]]))\n",
    "print('w_out=',W_out.shape)\n",
    "\n",
    "#recurrent bias\n",
    "b_hh = torch.Tensor(np.array([[0,0]]))\n",
    "print('b_hh=',b_hh.shape)\n",
    "\n",
    "#output bias\n",
    "b_out = torch.Tensor([0])\n",
    "print('b_out=',b_out.shape)\n",
    "\n",
    "rnn_model = make_rnn_from_networkparameters(W_in,W_hh,W_out,b_hh,b_out)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "#input_sequence = torch.Tensor([[1, 0], [0, 1], [1, 1]])  \n",
    "input_size = 2\n",
    "input_length = 3\n",
    "batch_size= 1\n",
    "output_size = 1\n",
    "input_sequence = torch.randn(batch_size, input_length, input_size)\n",
    "print('Input Sequence = ',input_sequence)\n",
    "\n",
    "#inicialize the hidden state\n",
    "hidden_state = rnn_model.init_hidden(input_sequence.size(0)) \n",
    "print('hidden state = ',hidden_state)\n",
    "\n",
    "target_output = torch.randn(batch_size,input_length,output_size)\n",
    "print('Target = ',target_output)\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------train-------------------\n",
    "#----------------------------------------\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()  #Clear gradients\n",
    "    hidden_state = rnn_model.init_hidden(input_sequence.size(0))  #initialize the hidden state for each epoch\n",
    "    outputs, hidden_state = rnn_model(input_sequence, hidden_state)  #forward pass\n",
    "    loss = criterion(outputs, target_sequence)\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    loss_vector.append(loss.item())\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "#save the training model  \n",
    "torch.save(rnn_model.state_dict(), 'trained_model.pth')\n",
    "\n",
    "#load the trained model\n",
    "rnn_model = make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out)\n",
    "rnn_model.load_state_dict(torch.load('trained_model.pth'))\n",
    "\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------test-------------------\n",
    "#----------------------------------------\n",
    "#evaluation mode\n",
    "rnn_model.eval()\n",
    "\n",
    "#forward pass on test input\n",
    "test_outputs, _ = rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0)))\n",
    "\n",
    "# Print the test outputs\n",
    "print(\"Test Outputs:\")\n",
    "print(test_outputs)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e07c2",
   "metadata": {},
   "source": [
    "## Same above but ussing pytorch.nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c18496f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_inn= torch.Size([2, 2])\n",
      "W_hh= torch.Size([2, 2])\n",
      "w_out= torch.Size([1, 2])\n",
      "b_hh= torch.Size([1, 2])\n",
      "b_out= torch.Size([1])\n",
      "Input Sequence =  tensor([[[-1.1016,  2.2448],\n",
      "         [-0.9452,  0.7219],\n",
      "         [ 0.2332, -1.3077]]])\n",
      "hidden state =  tensor([[[0., 0.]]])\n",
      "Target =  tensor([[[ 3.3463],\n",
      "         [ 1.6671],\n",
      "         [-1.5408]]])\n",
      "Epoch: 100/100, Loss: 4.110596179962158\n",
      "Test Outputs:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\2132052980.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\2132052980.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\2132052980.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\2132052980.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\2132052980.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 3, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1575]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAguUlEQVR4nO3de5hcdZ3n8fen70kn3ZBOk3QSQicYEaKJsr1BDAuCiqAI3nYGBXV98MnAwIqO621UVkZXx8dZl2UAY4ZBYBDY2dEIi4AgDqAgSoIBuQjG0EBIIJ2EpHPt63f/qNNJ0VR1qpM6XZ2qz+ux7Dq3Ot8jWJ/6/X7noojAzMxsuKpSF2BmZuOTA8LMzHJyQJiZWU4OCDMzy8kBYWZmOTkgzMwsJweEVSxJSyV9rdR1ZJP0nyQ9nTXdKemdyfuvS7qhdNVZpXFAWMllfwmOpYg4PyK+MdrtJP1A0vU55i+Q1CNpygHU9KuIOGp/t89H0r2SdkvaLmmjpJ9Iasta/nVJIek/Z82rSea1J9PXJtOLstZ5nSRfTFWmHBBmo3ct8EFJjcPmfxy4LSI2j31JBbkoIiYBrwMmAf8wbPlm4O8kVY/wGZuBb6ZUn40zDggbtyTVS7pM0rrkdZmk+mTZVEm3SdoiabOkX0mqSpZ9UdKLkrZJelrSO/J8/rWSvpm8f7uktZI+J2mDpPWSPplru4j4DfAi8KGsz6oGPgpcJ+lISb+UtCn5tf4jSYdkrdsp6b9JekzSVkn/R1JDdh0F/u/zfyW9lHzG/ZLmF7JdRGwBfgq8ediiO4Fe4NwRNr8OWCDppEL2ZQc3B4SNZ18B3krmi2whsAj4arLsc8BaoBWYBvwtEJKOAi4C/mNETAbeDXQWuL/pQDMwEzgPuFLSoXnWvZ5Mi2HIO4Fa4A5AwLeBGcDRwOHA14dt/xfAacAcYAHwXwqsMdsdwDzgMOAR4EeFbCSpBfggsHrYogC+Bvx3SbV5Nt8JfAv4H/tRrx1kHBA2np0D/F1EbIiILuBS4GPJsj6gDTgiIvqSvvsABoB64BhJtRHRGRF/LnB/fcn++iLidmA7kG884F+AkyTNSqY/DtyYbLs6Iu6OiJ6k7u8Bw39xXx4R65LuqP/Ha3/N71NEXBMR2yKih0wALZTUPMIml0vaCmwEpgL/Ncdn3gp0AZ8a4XN+AMyWdPpoa7aDiwPCxrMZwHNZ088l8wC+S+YX8F2S1kj6EkBErAY+Q+YLc4OkmyXNoDCbIqI/a3onmb7614iI54H7gXMlTQLeT6b7BUmHJft9UVI3cAOZL+RsLxWyn3wkVUv6e0l/TvbRmSwavp9sn46IZjItlkOBWXnW+yqZ1ltDroVJIH0jeWk0ddvBxQFh49k64Iis6dnJPJJfzp+LiLnA+4C/GRpriIgbI+KEZNsAvpNSfdeRaTl8CHg2Ih5J5n872e+CiGgi06df7C/SjwJnkenaagbak/n73E9E/IHMQPOVkl6zfkTcTSZ8/3qEj/lhst8PjKpqO6g4IGy8qJXUkPWqAW4CviqpVdJU4BIyv8aRdEZyiqWAbjJdSwOSjpJ0SjKYvRvYlSxLw4/JjC9cStJ6SEwm0z21RdJM4PMp7Hsy0ANsAiaSGRcYjevIjF2cmWf5V4Av5Ns4aWl9HfjiKPdrBxEHhI0Xt5P5Mh96fZ3Mr9wVwGPAH8gMxA6dYjkP+AWZL+LfAFdFxL1kxh/+nkw/+0tkvgT/No2CI2IHe0Mie4D4UuBYYCvwM+AnKez+ejJdbi8CTwIPjWbjiOgFLiczKJ1r+QPA7/bxMTcB60ezXzu4yA8MMjOzXNyCMDOznBwQZmaWkwPCzMxyckCYmVlONaUuoJimTp0a7e3tpS7DzOygsXLlyo0R0ZprWVkFRHt7OytWrCh1GWZmBw1Jz+Vb5i4mMzPLyQFhZmY5OSDMzCwnB4SZmeXkgDAzs5wcEGZmlpMDwszMcnJAAJff8yfue6ar1GWYmY0rDghg2f1ruO9pB4SZWTYHBNDUUEP37r5Sl2FmNq44IIDJDbVsc0CYmb2KAwJomlBD967+UpdhZjauOCBIWhA9bkGYmWVzQJCMQbgFYWb2Kqne7ltSJ7ANGAD6I6Jj2PLPA+dk1XI00BoRm/e1bTF5DMLM7LXG4nkQJ0fExlwLIuK7wHcBJL0P+GxEbC5k22JqmlBD9+5+IgJJae/OzOygMJ66mD4C3FSKHTc11DIwGOzqGyjF7s3MxqW0AyKAuyStlLQk30qSJgKnAT8e7bbFMLmhFsDjEGZmWdLuYlocEeskHQbcLemPEXF/jvXeBzwwrHupoG2T8FgCMHv27P0qsmlC5n+G7t19TG9u2K/PMDMrN6m2ICJiXfJ3A7AcWJRn1bMZ1r1U6LYRsSwiOiKio7U153O392moBeGBajOzvVILCEmNkiYPvQdOBR7PsV4zcBJwy2i3LZamhqQF4S4mM7M90uximgYsT84KqgFujIg7JZ0PEBFLk/U+ANwVETv2tW1ahe4Zg3ALwsxsj9QCIiLWAAtzzF86bPpa4NpCtk3L3jEItyDMzIaMp9NcS6bJYxBmZq/hgADqa6qoq67yGISZWRYHBCCJyQ01bkGYmWVxQCSaJtR6DMLMLIsDIuEWhJnZqzkgEk0NtXTvckCYmQ1xQCSG7uhqZmYZDojE5Ho/E8LMLJsDIuHnUpuZvZoDIjG5oZZdfQP0DQyWuhQzs3HBAZEYumHfNo9DmJkBDog9fMtvM7NXc0Akmib4qXJmZtkcEInJe7qY3IIwMwMHxB5NfiaEmdmrOCASQy0IXyxnZpbhgEjsHYNwC8LMDBwQe0yqdwvCzCybAyJRXSUm1/uOrmZmQxwQWZom1Po0VzOzRKoBIalT0h8krZK0Isfyt0vamixfJemSrGWnSXpa0mpJX0qzziF+JoSZ2V41Y7CPkyNi4wjLfxURZ2TPkFQNXAm8C1gLPCzp1oh4MsU6M8+EcECYmQHjt4tpEbA6ItZERC9wM3BW2jvNtCDcxWRmBukHRAB3SVopaUmedY6X9KikOyTNT+bNBF7IWmdtMu81JC2RtELSiq6urgMqNvNcarcgzMwg/S6mxRGxTtJhwN2S/hgR92ctfwQ4IiK2S3oP8FNgHqAcnxW5dhARy4BlAB0dHTnXKZRbEGZme6XagoiIdcnfDcByMl1H2cu7I2J78v52oFbSVDIthsOzVp0FrEuzVsiMQWzb3U/EAeWMmVlZSC0gJDVKmjz0HjgVeHzYOtMlKXm/KKlnE/AwME/SHEl1wNnArWnVOmRyQw0Dg8HO3oG0d2VmNu6l2cU0DViefP/XADdGxJ2SzgeIiKXAh4ELJPUDu4CzI/PzvV/SRcDPgWrgmoh4IsVagazbbezuo7F+LE7wMjMbv1L7FoyINcDCHPOXZr2/Argiz/a3A7enVV8ue27Yt6uftuax3LOZ2fgzXk9zLYkmP1XOzGwPB0SW7C4mM7NK54DIsvepcj7V1czMAZFlz1Pl/EwIMzMHRDY/Vc7MbC8HRJaG2mrqaqo8BmFmhgPiNZoaavxMCDMzHBCvccjEOrbs7C11GWZmJeeAGGZKYx2bdjggzMwcEMO0NNax2QFhZuaAGK5lUh2btveUugwzs5JzQAwzpbGeLbv6GBj0Lb/NrLI5IIZpaawjAl7xQLWZVTgHxDAtk+oAPA5hZhXPATHMlMZMQGz0OISZVTgHxDAtjfWAWxBmZg6IYYZaEA4IM6t0DohhDp1YiwQbtzsgzKyyOSCGqamu4pAJtWze4TEIM6tsDogcpvhqajMzatL8cEmdwDZgAOiPiI5hy88BvphMbgcuiIhHC9k2TS2T6tnkLiYzq3CpBkTi5IjYmGfZs8BJEfGKpNOBZcBxBW6bmpbGOv60YftY79bMbFwZi4DIKyIezJp8CJhVqlqyuYvJzCz9MYgA7pK0UtKSfax7HnDHaLeVtETSCkkrurq6ilBypgXxys5e34/JzCpa2i2IxRGxTtJhwN2S/hgR9w9fSdLJZALihNFuGxHLyHRN0dHRUZRv9JZJ9XvuxzR1Un0xPtLM7KCTagsiItYlfzcAy4FFw9eRtAC4GjgrIjaNZtu0+GI5M7MUA0JSo6TJQ++BU4HHh60zG/gJ8LGIeGY026apJQkIn8lkZpUszS6macBySUP7uTEi7pR0PkBELAUuAVqAq5L1hk5nzbltirW+Sssk34/JzCy1gIiINcDCHPOXZr3/FPCpQrcdK0NdTJt8NbWZVTBfSZ3DoRNrAXcxmVllc0DkUFNdxSETa93FZGYVzQGRR0tjnbuYzKyiOSDyaGn0/ZjMrLI5IPLw7TbMrNI5IPJomeSAMLPK5oDIo6Wxjs2+H5OZVTAHRB5TGuuIgC073Yows8rkgMjDV1ObWaVzQOQxdD+mjT6TycwqlAMijymTfEdXM6tsDog89t7y2xfLmVllckDkMWXi0A373IIws8rkgMhj6H5MvprazCqVA2IEU3w/JjOrYA6IEUyb3MCGbgeEmVUmB8QI2pobWL91d6nLMDMrCQfECKY3N/By927fbsPMKlJBASGpUVJV8v71ks6UVJtuaaXX1txA/2Cwabu7mcys8hTagrgfaJA0E7gH+CRwbVpFjRdtzRMA3M1kZhWp0IBQROwEPgj8Y0R8ADhmnxtJnZL+IGmVpBU5lkvS5ZJWS3pM0rFZy06T9HSy7EuFHlAxTW9uABwQZlaZagpcT5KOB84BzhvltidHxMY8y04H5iWv44DvA8dJqgauBN4FrAUelnRrRDxZ4D6Lom1PQOway92amY0LhbYgPgN8GVgeEU9Imgv8exH2fxZwfWQ8BBwiqQ1YBKyOiDUR0QvcnKw7pqY01lFXU8VLbkGYWQUqqBUQEfcB9wEkg9UbI+LThWwK3CUpgB9ExLJhy2cCL2RNr03m5Zp/XK4dSFoCLAGYPXt2ASUVTpJPdTWzilXoWUw3SmqS1Ag8CTwt6fMFbLo4Io4l05V0oaQTh390jm1ihPmvnRmxLCI6IqKjtbW1gJJGZ3pTg1sQZlaRCu1iOiYiuoH3A7cDs4GP7WujiFiX/N0ALCfTdZRtLXB41vQsYN0I88dcW3MD67s9BmFmlafQgKhNrnt4P3BLRPSR5xf9kOTaiclD74FTgceHrXYr8PHkbKa3AlsjYj3wMDBP0hxJdcDZybpjbnrzBF7auptBXyxnZhWm0DORfgB0Ao8C90s6AujexzbTgOWShvZzY0TcKel8gIhYSqY18h5gNbCTzPUVRES/pIuAnwPVwDUR8cQojqto2pob6BsINu3opXVyfSlKMDMriUIHqS8HLs+a9Zykk/exzRpgYY75S7PeB3Bhnu1vJxMgJTV0qutLW3c7IMysohQ6SN0s6XuSViSv/wk0plzbuLD3amqPQ5hZZSl0DOIaYBvwF8mrG/hhWkWNJ76a2swqVaFjEEdGxIeypi+VtCqFesadlsY6aqvlgDCzilNoC2KXpBOGJiQtBiqiz6WqSkxvbuAldzGZWYUptAVxPnC9pOZk+hXgE+mUNP60NU1wC8LMKk5BLYiIeDQiFgILgAUR8RbglFQrG0emNzfwUrcDwswqy6ieKBcR3ckV1QB/k0I949LQ/ZgyZ+WamVWGA3nkaK77JZWl6c0N9PYPsnlHb6lLMTMbMwcSEBXzc9pPljOzSjTiILWkbeQOAgETUqloHMq+mvqNM5v3sbaZWXkYMSAiYvJYFTKe+clyZlaJDqSLqWK0TKqnpsoXy5lZZXFAFKC6Skzzg4PMrMI4IArU1tzAOncxmVkFcUAU6PApE3l+085Sl2FmNmYcEAVqb2lk3dbd7O4bKHUpZmZjwgFRoPapEwF4zq0IM6sQDogCzZmaeT7Ssxt3lLgSM7Ox4YAoUHsSEJ2bHBBmVhkKvd33fpNUDawAXoyIM4Yt+zxwTlYtRwOtEbFZUieZp9gNAP0R0ZF2rSNpaqilpbGOTrcgzKxCpB4QwMXAU0DT8AUR8V3guwCS3gd8NiI2Z61yckRsHIMaC9I+tdFdTGZWMVLtYpI0C3gvcHUBq38EuCnNeg5Ue0uju5jMrGKkPQZxGfAFYHCklSRNBE4Dfpw1O4C7JK2UtGSEbZdIWiFpRVdXVxFKzm/O1Im83N3Dzt7+VPdjZjYepBYQks4ANkTEygJWfx/wwLDupcURcSxwOnChpBNzbRgRyyKiIyI6WltbD7zwEQwNVPtUVzOrBGm2IBYDZyaDzTcDp0i6Ic+6ZzOseyki1iV/NwDLgUXplVqY9pbkTCaPQ5hZBUgtICLiyxExKyLayQTALyPi3OHrSWoGTgJuyZrXKGny0HvgVODxtGot1FAL4lmPQ5hZBRiLs5heRdL5ABGxNJn1AeCuiMj+1p0GLJcEmRpvjIg7x7TQHCbV1zB1Ur1bEGZWEcYkICLiXuDe5P3SYcuuBa4dNm8NsHAsahutOVMn0rnRYxBmVv58JfUotbc0uovJzCqCA2KU2qc20rWth+09PtXVzMqbA2KUhm7a53EIMyt3DohR2nOqq7uZzKzMOSBGaei5EG5BmFm5c0CM0sS6Gg6bXE+nr6Y2szLngNgP7VMb3YIws7LngNgPrztsEs+8vI2IKHUpZmapcUDsh2Pamuje3c/aV3aVuhQzs9Q4IPbD/BmZZx89ub67xJWYmaXHAbEf3jC9iSrBE+scEGZWvhwQ+2FCXTVzWyfxpAPCzMqYA2I/HdPWxJPrtpa6DDOz1Dgg9tP8GU2s27qbV3b0lroUM7NUOCD20zHJQPVTHqg2szLlgNhPx7RlAsID1WZWrhwQ+6llUj3Tmxp8qquZlS0HxAE4ZkYTT3ig2szKlAPiAMyf0cSfu3awu2+g1KWYmRWdA+IAHNPWxMBg8MzL20pdiplZ0aUeEJKqJf1e0m05lr1d0lZJq5LXJVnLTpP0tKTVkr6Udp37Y/6MZsAD1WZWnmrGYB8XA08BTXmW/yoizsieIakauBJ4F7AWeFjSrRHxZKqVjtKsQycwub7GV1SbWVlKtQUhaRbwXuDqUW66CFgdEWsiohe4GTir2PUdqKoqcbQHqs2sTKXdxXQZ8AVgcIR1jpf0qKQ7JM1P5s0EXshaZ20y7zUkLZG0QtKKrq6uYtQ8Km+c0cyT67vp6fdAtZmVl9QCQtIZwIaIWDnCao8AR0TEQuAfgZ8ObZ5j3ZxP54mIZRHREREdra2tB1Lyfjlu7hR29w3y2Fq3IsysvKTZglgMnCmpk0wX0SmSbsheISK6I2J78v52oFbSVDIthsOzVp0FrEux1v123JwpSPDQnzeVuhQzs6JKLSAi4ssRMSsi2oGzgV9GxLnZ60iaLknJ+0VJPZuAh4F5kuZIqku2vzWtWg/EIRPreMP0Jh561gFhZuVlLM5iehVJ5wNExFLgw8AFkvqBXcDZkXnQc7+ki4CfA9XANRHxxFjXWqi3zp3Cjb99np7+AeprqktdjplZUYxJQETEvcC9yfulWfOvAK7Is83twO1jUN4BO35uCz98oJNHX9jKojlTSl2OmVlR+ErqIlg0NA6xxt1MZlY+HBBFcMjEOo6e3sRvPFBtZmXEAVEkb53bwiPPv+Ib95lZ2XBAFMnxR7bQ0z/Ioy9sKXUpZmZF4YAokkXtmXGI33gcwszKhAOiSJon1nJMW5MHqs2sbDggiuj4uS088vwWtvf0l7oUM7MD5oAoolPnT6e3f5B7nnq51KWYmR0wB0QRdRxxKNOa6rntsfWlLsXM7IA5IIqoqkq8501t3Pd0F9t295W6HDOzA+KAKLIzFrTROzDI3U+6m8nMDm4OiCJ7y+GHMqO5gZ+5m8nMDnIOiCIb6ma6/09dbN3pbiYzO3g5IFJwxsIZ9A0Edz35UqlLMTPbbw6IFCyc1cysQyf4bCYzO6g5IFIgifcuaOOB1RvZ0L271OWYme0XB0RKPrpoNoMRXPNAZ6lLMTPbLw6IlBzR0sjpb2rjRw8952sizOyg5IBI0V+dOJdtPf3c9LvnS12KmdmoOSBStGDWIbztyBb++dfP0ts/WOpyzMxGJfWAkFQt6feSbsux7BxJjyWvByUtzFrWKekPklZJWpF2nWn5q5OO5OXuHn666sVSl2JmNipj0YK4GHgqz7JngZMiYgHwDWDZsOUnR8SbI6IjzQLTdOK8qRzd1sSy+9cwOBilLsfMrGCpBoSkWcB7gatzLY+IByPilWTyIWBWmvWUgiT++u1HsnrDdm5++IVSl2NmVrC0WxCXAV8ACumAPw+4I2s6gLskrZS0JN9GkpZIWiFpRVdX1wEVm5YzFrTxtiNb+PbtT/Gyr4sws4NEagEh6QxgQ0SsLGDdk8kExBezZi+OiGOB04ELJZ2Ya9uIWBYRHRHR0draWozSi04S3/rAm+gdGOSSWx4vdTlmZgVJswWxGDhTUidwM3CKpBuGryRpAZkuqLMiYs8DnSNiXfJ3A7AcWJRiralrn9rIZ9/1en7+xMvc+bhvwWFm419qARERX46IWRHRDpwN/DIizs1eR9Js4CfAxyLimaz5jZImD70HTgUO+p/enzphDvNnNHHJLU+weUdvqcsxMxvRmF8HIel8Secnk5cALcBVw05nnQb8WtKjwO+An0XEnWNda7HVVFfxnQ8tYMuuPs677mF29Q6UuiQzs7wUUT6nXnZ0dMSKFeP/kok7H1/PBT96hHe8YRpLzz2Wmmpfr2hmpSFpZb5LCfzNVAKnvbGNS8+czy+eepmv3fIE5RTSZlY+akpdQKX6+PHtvLR1N1fd+2d6+gb41gffRENtdanLMjPbwwFRQp9/91E01Fbzv37xDE+/vI0ffOw/MOvQiaUuy8wMcBdTSUni0++Yx9Uf7+D5TTs584oHuGXVi+5yMrNxwQExDrzj6GncctFiZhzSwMU3r+IDVz3Iyude2feGZmYpckCME3NbJ3HrhSfw3Q8vYN2WXXzo+w/y0X96iNseW+dbhZtZSfg013FoR08/1z7YyY2/fZ4Xt+yipbGOU+dP56TXt7L4dS1MbqgtdYlmViZGOs3VATGODQwGv/pTF/+64gXuf2Yj23v6qakSR7c18caZzbxpZjNHTZ/EES2NtDTWIanUJZvZQcYBUQb6BgZ55LlXuO+ZLla9sIXHX9xK9+7+Pcsn1dcw85AJHNZUT+vkelon1dM8sZZDJtTRNKGGxvoaGutqmFhXTUNtNQ21VdTXVFNXU0VddRW11aK6Sg4ZswozUkD4NNeDRG11FcfNbeG4uS0ARATPb97Jmq4ddG7awXObdrJuyy5e3tbD6g3b2bSjd7/GLqqrMkFRUyWqJaqS6SplzrqqEoi90wBS8kLJ3732rLPnv3LLtU1aHIFWbg6dWMe/nn980T/XAXGQksQRLY0c0dKYd53dfQNs2dlH9+4+tvf0s7NngB29/fT0D7K7b4CevgF6B4K+gUF6+wfpHwwGBjN/Bwdjz9/BgMEIBiOIPe8hAoIg+Q8RQXZ7dKhxOrQsn8g7UXyR9g7MSqAppXFJB0QZa6itZnpzNdObG0pdipkdhHyaq5mZ5eSAMDOznBwQZmaWkwPCzMxyckCYmVlODggzM8vJAWFmZjk5IMzMLKeyuheTpC7guf3cfCqwsYjlHAwq8ZihMo+7Eo8ZKvO4R3vMR0REa64FZRUQB0LSinw3rCpXlXjMUJnHXYnHDJV53MU8ZncxmZlZTg4IMzPLyQGx17JSF1AClXjMUJnHXYnHDJV53EU7Zo9BmJlZTm5BmJlZTg4IMzPLqeIDQtJpkp6WtFrSl0pdT1okHS7p3yU9JekJSRcn86dIulvSn5K/h5a61mKTVC3p95JuS6Yr4ZgPkfRvkv6Y/DM/vtyPW9Jnk3+3H5d0k6SGcjxmSddI2iDp8ax5eY9T0peT77enJb17NPuq6ICQVA1cCZwOHAN8RNIxpa0qNf3A5yLiaOCtwIXJsX4JuCci5gH3JNPl5mLgqazpSjjm/w3cGRFvABaSOf6yPW5JM4FPAx0R8UagGjib8jzma4HThs3LeZzJ/8fPBuYn21yVfO8VpKIDAlgErI6INRHRC9wMnFXimlIREesj4pHk/TYyXxgzyRzvdclq1wHvL0mBKZE0C3gvcHXW7HI/5ibgROCfASKiNyK2UObHTeYRyhMk1QATgXWU4TFHxP3A5mGz8x3nWcDNEdETEc8Cq8l87xWk0gNiJvBC1vTaZF5Zk9QOvAX4LTAtItZDJkSAw0pYWhouA74ADGbNK/djngt0AT9MutaultRIGR93RLwI/APwPLAe2BoRd1HGxzxMvuM8oO+4Sg8I5ZhX1uf9SpoE/Bj4TER0l7qeNEk6A9gQEStLXcsYqwGOBb4fEW8BdlAeXSt5JX3uZwFzgBlAo6RzS1vVuHBA33GVHhBrgcOzpmeRaZaWJUm1ZMLhRxHxk2T2y5LakuVtwIZS1ZeCxcCZkjrJdB+eIukGyvuYIfPv9dqI+G0y/W9kAqOcj/udwLMR0RURfcBPgLdR3secLd9xHtB3XKUHxMPAPElzJNWRGcy5tcQ1pUKSyPRJPxUR38tadCvwieT9J4Bbxrq2tETElyNiVkS0k/ln+8uIOJcyPmaAiHgJeEHSUcmsdwBPUt7H/TzwVkkTk3/X30FmnK2cjzlbvuO8FThbUr2kOcA84HcFf2pEVPQLeA/wDPBn4CulrifF4zyBTNPyMWBV8noP0ELmrIc/JX+nlLrWlI7/7cBtyfuyP2bgzcCK5J/3T4FDy/24gUuBPwKPA/8C1JfjMQM3kRln6SPTQjhvpOMEvpJ8vz0NnD6afflWG2ZmllOldzGZmVkeDggzM8vJAWFmZjk5IMzMLCcHhJmZ5eSAMBsFSQOSVmW9inaFsqT27Dt0mpVaTakLMDvI7IqIN5e6CLOx4BaEWRFI6pT0HUm/S16vS+YfIekeSY8lf2cn86dJWi7p0eT1tuSjqiX9U/Jcg7skTSjZQVnFc0CYjc6EYV1Mf5m1rDsiFgFXkLmLLMn76yNiAfAj4PJk/uXAfRGxkMx9kp5I5s8DroyI+cAW4EOpHo3ZCHwltdkoSNoeEZNyzO8ETomINclNEV+KiBZJG4G2iOhL5q+PiKmSuoBZEdGT9RntwN2ReegLkr4I1EbEN8fg0Mxewy0Is+KJPO/zrZNLT9b7ATxOaCXkgDArnr/M+vub5P2DZO4kC3AO8Ovk/T3ABbDnmdlNY1WkWaH868RsdCZIWpU1fWdEDJ3qWi/pt2R+eH0kmfdp4BpJnyfzlLdPJvMvBpZJOo9MS+ECMnfoNBs3PAZhVgTJGERHRGwsdS1mxeIuJjMzy8ktCDMzy8ktCDMzy8kBYWZmOTkgzMwsJweEmZnl5IAwM7Oc/j9vNiB4vcEGXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#vanilla structure normal\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,num_layers, transform_function='relu'):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.transform_function = transform_function\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        out, hidden = self.rnn(inputs, hidden)\n",
    "        #out = F.relu(out) #apply transformation function\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function='relu'):\n",
    "    \n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0] \n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out,num_layers=1, transform_function=transform_function)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "    \n",
    "    return rnn_model\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------parameters-------------\n",
    "#----------------------------------------\n",
    "\n",
    "#input weight matrix\n",
    "W_in = torch.eye(2)\n",
    "print('W_inn=',W_in.shape)\n",
    "\n",
    "#recurrent weight matrix\n",
    "W_hh = torch.eye(2)\n",
    "print('W_hh=',W_hh.shape)\n",
    "\n",
    "#output weitght matrix\n",
    "W_out = torch.Tensor(np.array([[-1,1]]))\n",
    "print('w_out=',W_out.shape)\n",
    "\n",
    "#recurrent bias\n",
    "b_hh = torch.Tensor(np.array([[0,0]]))\n",
    "print('b_hh=',b_hh.shape)\n",
    "\n",
    "#output bias\n",
    "b_out = torch.Tensor([0])\n",
    "print('b_out=',b_out.shape)\n",
    "\n",
    "rnn_model = make_rnn_from_networkparameters(W_in,W_hh,W_out,b_hh,b_out)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "#input_sequence = torch.Tensor([[1, 0], [0, 1], [1, 1]])  \n",
    "input_size = 2\n",
    "input_length = 3\n",
    "batch_size= 1\n",
    "output_size = 1\n",
    "input_sequence = torch.randn(batch_size, input_length, input_size)\n",
    "print('Input Sequence = ',input_sequence)\n",
    "#print('Input Sequence[0][1][0] = ',input_sequence[0][1][0])\n",
    "#print('Input Sequence[0][1][1] = ',input_sequence[0][1][1])\n",
    "\n",
    "#inicialize the hidden state\n",
    "hidden_state = rnn_model.init_hidden(input_sequence.size(0)) \n",
    "print('hidden state = ',hidden_state)\n",
    "\n",
    "t = torch.zeros(1,input_length, input_size-1)\n",
    "targets = t.numpy()\n",
    "\n",
    "#calculate target_output depending on the input sequence\n",
    "for i in range(input_length):\n",
    "    targets[0][i]=input_sequence[0][i][1].item()-input_sequence[0][i][0].item()\n",
    "target_output = torch.from_numpy(targets)\n",
    "#target_output = torch.randn(batch_size,input_length,output_size)\n",
    "print('Target = ',target_output)\n",
    "\n",
    "num_epochs = 100\n",
    "#----------------------------------------\n",
    "# ----------------train-------------------\n",
    "#----------------------------------------\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, hidden = rnn_model(input_sequence, hidden_state)\n",
    "    loss = criterion(outputs, target_output)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_vector.append(loss.item())\n",
    "    # Print the training loss for every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------test-------------------\n",
    "#----------------------------------------\n",
    "#evaluation mode\n",
    "rnn_model.eval()\n",
    "\n",
    "#forward pass on test input\n",
    "test_outputs, _ = rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0)))\n",
    "\n",
    "# Print the test outputs\n",
    "print(\"Test Outputs:\")\n",
    "print(test_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c82075",
   "metadata": {},
   "source": [
    "# 27/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "855c1ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_inn= torch.Size([2, 2])\n",
      "W_hh= torch.Size([2, 2])\n",
      "w_out= torch.Size([1, 2])\n",
      "b_hh= torch.Size([1, 2])\n",
      "b_out= torch.Size([1])\n",
      "Input Sequence =  tensor([[[0.1621, 0.1753],\n",
      "         [1.3971, 1.3535],\n",
      "         [0.1488, 1.6638]]])\n",
      "hidden state =  tensor([[[0., 0.]]])\n",
      "Target =  tensor([[[ 0.0132],\n",
      "         [-0.0436],\n",
      "         [ 1.5150]]])\n",
      "Epoch: 100/100, Loss: 0.5208930373191833\n",
      "Test Outputs:\n",
      "tensor([[0.4948]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\3830348641.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\3830348641.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\3830348641.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\3830348641.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\3830348641.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 3, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#vanilla structure normal\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,num_layers, transform_function='relu'):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.transform_function = transform_function\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers,nonlinearity='relu', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        out, hidden = self.rnn(inputs, hidden)\n",
    "        #out = F.relu(out) #apply transformation function\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function='relu'):\n",
    "    \n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0] \n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out,num_layers=1, transform_function=transform_function)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "    \n",
    "    return rnn_model\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------parameters-------------\n",
    "#----------------------------------------\n",
    "\n",
    "#input weight matrix\n",
    "W_in = torch.eye(2)\n",
    "print('W_inn=',W_in.shape)\n",
    "\n",
    "#recurrent weight matrix\n",
    "W_hh = torch.eye(2)\n",
    "print('W_hh=',W_hh.shape)\n",
    "\n",
    "#output weitght matrix\n",
    "W_out = torch.Tensor(np.array([[-1,1]]))\n",
    "print('w_out=',W_out.shape)\n",
    "\n",
    "#recurrent bias\n",
    "b_hh = torch.Tensor(np.array([[0,0]]))\n",
    "print('b_hh=',b_hh.shape)\n",
    "\n",
    "#output bias\n",
    "b_out = torch.Tensor([0])\n",
    "print('b_out=',b_out.shape)\n",
    "\n",
    "rnn_model = make_rnn_from_networkparameters(W_in,W_hh,W_out,b_hh,b_out)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "#input_sequence = torch.Tensor([[1, 0], [0, 1], [1, 1]])  \n",
    "input_size = 2\n",
    "input_length = 3\n",
    "batch_size= 1\n",
    "output_size = 1\n",
    "input_sequence = abs(torch.randn(batch_size, input_length, input_size))\n",
    "print('Input Sequence = ',input_sequence)\n",
    "#print('Input Sequence[0][1][0] = ',input_sequence[0][1][0])\n",
    "#print('Input Sequence[0][1][1] = ',input_sequence[0][1][1])\n",
    "\n",
    "#inicialize the hidden state\n",
    "hidden_state = rnn_model.init_hidden(input_sequence.size(0)) \n",
    "print('hidden state = ',hidden_state)\n",
    "\n",
    "t = torch.zeros(1,input_length, input_size-1)\n",
    "targets = t.numpy()\n",
    "\n",
    "#calculate target_output depending on the input sequence\n",
    "for i in range(input_length):\n",
    "    targets[0][i]=input_sequence[0][i][1].item()-input_sequence[0][i][0].item()\n",
    "target_output = torch.from_numpy(targets)\n",
    "#target_output = torch.randn(batch_size,input_length,output_size)\n",
    "print('Target = ',target_output)\n",
    "transform_function = nn.ReLU()\n",
    "num_epochs = 100\n",
    "#----------------------------------------\n",
    "# ----------------train-------------------\n",
    "#----------------------------------------\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, hidden = rnn_model(input_sequence, hidden_state)\n",
    "    loss = criterion(outputs, target_output)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_vector.append(loss.item())\n",
    "    # Print the training loss for every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------test-------------------\n",
    "#----------------------------------------\n",
    "#evaluation mode\n",
    "rnn_model.eval()\n",
    "\n",
    "#forward pass on test input\n",
    "test_outputs, _ = rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0)))\n",
    "\n",
    "# Print the test outputs\n",
    "print(\"Test Outputs:\")\n",
    "print(test_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba0699",
   "metadata": {},
   "source": [
    "integrating the target e adicionar a nao linearidade da função de transformação à parte de formação do rnn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e821e72d",
   "metadata": {},
   "source": [
    "### Identity RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2af9555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_inn= tensor([[1., 0.],\n",
      "        [0., 1.]])\n",
      "W_hh= tensor([[1., 0.],\n",
      "        [0., 1.]])\n",
      "w_out= tensor([[-1.,  1.]])\n",
      "b_hh= tensor([[0., 0.]])\n",
      "b_out= tensor([0.])\n",
      "Input Sequence =  tensor([[[1.7970, 1.2978],\n",
      "         [0.5991, 0.5385],\n",
      "         [1.7834, 2.4223]]])\n",
      "hidden state =  tensor([[[0., 0.]]])\n",
      "Target =  tensor([[[-0.4992],\n",
      "         [-0.0606],\n",
      "         [ 0.6389]]])\n",
      "Target Sum =  tensor(0.0791)\n",
      "Epoch: 100/100, Loss: 0.21976880729198456\n",
      "Test Outputs:\n",
      "tensor([[0.0367]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1110705362.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1110705362.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1110705362.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\1110705362.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 3, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#vanilla structure normal\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,num_layers, transform_function='relu'):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.transform_function = transform_function\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1,nonlinearity='relu', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        out, hidden = self.rnn(inputs, hidden)\n",
    "        #out = F.relu(out) #apply transformation function\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function='relu'):\n",
    "    \n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0] \n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out,num_layers=1, transform_function=transform_function)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.zeros_like(b_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_hh_l0 = nn.Parameter(torch.tensor(b_hh, dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "    \n",
    "    return rnn_model\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------parameters-------------\n",
    "#----------------------------------------\n",
    "\n",
    "#input weight matrix\n",
    "W_in = torch.eye(2)\n",
    "print('W_inn=',W_in.shape)\n",
    "\n",
    "#recurrent weight matrix\n",
    "W_hh = torch.eye(2)\n",
    "print('W_hh=',W_hh.shape)\n",
    "\n",
    "#output weitght matrix\n",
    "W_out = torch.Tensor(np.array([[-1,1]]))\n",
    "print('w_out=',W_out.shape)\n",
    "\n",
    "#recurrent bias\n",
    "b_hh = torch.Tensor(np.array([[0,0]]))\n",
    "print('b_hh=',b_hh.shape)\n",
    "\n",
    "#output bias\n",
    "b_out = torch.Tensor([0])\n",
    "print('b_out=',b_out.shape)\n",
    "\n",
    "rnn_model = make_rnn_from_networkparameters(W_in,W_hh,W_out,b_hh,b_out)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "#input_sequence = torch.Tensor([[1, 0], [0, 1], [1, 1]])  \n",
    "input_size = 2\n",
    "input_length = 3\n",
    "batch_size= 1\n",
    "output_size = 1\n",
    "input_sequence = abs(torch.randn(batch_size, input_length, input_size))\n",
    "\n",
    "#inicialize the hidden state\n",
    "hidden_state = rnn_model.init_hidden(input_sequence.size(0)) \n",
    "\n",
    "t = torch.zeros(1,input_length, input_size-1)\n",
    "targets = t.numpy()\n",
    "\n",
    "#calculate target_output depending on the input sequence\n",
    "for i in range(input_length):\n",
    "    targets[0][i]=input_sequence[0][i][1].item()-input_sequence[0][i][0].item()\n",
    "targets_n = np.cumsum(targets)\n",
    "target_output = torch.from_numpy(targets_n )\n",
    "\n",
    "print('hidden state = ',hidden_state)\n",
    "print('Input Sequence = ',input_sequence)\n",
    "print('Target = ',target_output)\n",
    "\n",
    "num_epochs = 100\n",
    "#----------------------------------------\n",
    "# ----------------train-------------------\n",
    "#----------------------------------------\n",
    "pl_output = []\n",
    "pl_targets = []\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, hidden = rnn_model(input_sequence, hidden_state)\n",
    "    #pl_output.append(outputs.item())\n",
    "    \n",
    "    loss = criterion(outputs, target_output)\n",
    "    #pl_targets.append(target_output1)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vector.append(loss.item())\n",
    "    # Print the training loss for every 100 epochs\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "        \n",
    "print('Outputs=',outputs)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.subplot(121)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------test-------------------\n",
    "#----------------------------------------\n",
    "#evaluation mode\n",
    "rnn_model.eval()\n",
    "\n",
    "#forward pass on test input\n",
    "test_outputs, _ = rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0)))\n",
    "#print(rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0))))\n",
    "# Print the test outputs\n",
    "print(\"Test Outputs:\",test_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3650fe6",
   "metadata": {},
   "source": [
    "## unbounded line attractor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26a4cabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_inn= tensor([[-1.,  1.],\n",
      "        [ 1., -1.]])\n",
      "W_hh= tensor([[0., 1.],\n",
      "        [1., 0.]])\n",
      "w_out= tensor([[0.5000, 0.5000]])\n",
      "b_hh= tensor([[0., 0.]])\n",
      "b_out= tensor([-100.])\n",
      "Input Sequence =  tensor([[[1.3948, 1.8640],\n",
      "         [0.1128, 0.0860],\n",
      "         [0.7297, 1.5044]]])\n",
      "hidden state =  tensor([[[0., 0.]]])\n",
      "Target =  tensor([[[ 0.4691],\n",
      "         [-0.0268],\n",
      "         [ 0.7747]]])\n",
      "Target Sum =  tensor(1.2171)\n",
      "Epoch: 100/100, Loss: 507.5577087402344\n",
      "Test Outputs:\n",
      "tensor([[-21.6704]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\166986211.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\166986211.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\166986211.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_14456\\166986211.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1, 3, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#vanilla structure normal\n",
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,num_layers, transform_function='relu'):\n",
    "        super(VanillaRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.transform_function = transform_function\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1,nonlinearity='relu', batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        out, hidden = self.rnn(inputs, hidden)\n",
    "        #out = F.relu(out) #apply transformation function\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
    "\n",
    "def make_rnn_from_networkparameters(W_in, W_hh, W_out, b_hh, b_out, transform_function='relu'):\n",
    "    \n",
    "    N_in = W_in.shape[1]\n",
    "    N_out = W_out.shape[0]\n",
    "    N_rec = W_hh.shape[0] \n",
    "    rnn_model = VanillaRNN(N_in, N_rec, N_out,num_layers=1, transform_function=transform_function)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        rnn_model.rnn.weight_ih_l0 = nn.Parameter(torch.tensor(W_in, dtype=torch.float))\n",
    "        rnn_model.rnn.weight_hh_l0 = nn.Parameter(torch.tensor(W_hh, dtype=torch.float))\n",
    "        rnn_model.rnn.bias_ih_l0 = nn.Parameter(torch.zeros_like(b_hh, dtype=torch.float))\n",
    "        rnn_model.fc.weight = nn.Parameter(torch.tensor(W_out, dtype=torch.float))\n",
    "        rnn_model.fc.bias = nn.Parameter(torch.tensor(b_out, dtype=torch.float))\n",
    "    \n",
    "    return rnn_model\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------parameters-------------\n",
    "#----------------------------------------\n",
    "\n",
    "#define alpha & beta\n",
    "#beta/alpha capacity\n",
    "alpha = 1 # difference between two channels\n",
    "beta = 100 # \n",
    "\n",
    "#input weight matrix\n",
    "W_in = alpha*torch.Tensor(np.array([[-1,1],[1,-1]]))\n",
    "print('W_inn=',W_in)\n",
    "\n",
    "#recurrent weight matrix\n",
    "W_hh = torch.Tensor(np.array([[0,1],[1,0]]))\n",
    "print('W_hh=',W_hh)\n",
    "\n",
    "#output weitght matrix\n",
    "W_out = (1/(2*alpha))*torch.Tensor(np.array([[1,1]]))\n",
    "print('w_out=',W_out)\n",
    "\n",
    "#recurrent bias\n",
    "b_hh = torch.Tensor(np.array([[0,0]]))\n",
    "print('b_hh=',b_hh)\n",
    "\n",
    "#output bias\n",
    "b_out = torch.Tensor([-beta/alpha])\n",
    "print('b_out=',b_out)\n",
    "\n",
    "rnn_model = make_rnn_from_networkparameters(W_in,W_hh,W_out,b_hh,b_out)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(rnn_model.parameters(), lr=0.01)\n",
    "\n",
    "#input_sequence = torch.Tensor([[1, 0], [0, 1], [1, 1]])  \n",
    "input_size = 2\n",
    "input_length = 3\n",
    "batch_size= 1\n",
    "output_size = 1\n",
    "input_sequence = abs(torch.randn(batch_size, input_length, input_size))\n",
    "print('Input Sequence = ',input_sequence)\n",
    "#print('Input Sequence[0][1][0] = ',input_sequence[0][1][0])\n",
    "#print('Input Sequence[0][1][1] = ',input_sequence[0][1][1])\n",
    "\n",
    "#inicialize the hidden state\n",
    "hidden_state = rnn_model.init_hidden(input_sequence.size(0)) \n",
    "print('hidden state = ',hidden_state)\n",
    "\n",
    "t = torch.zeros(1,input_length, input_size-1)\n",
    "targets = t.numpy()\n",
    "\n",
    "#calculate target_output depending on the input sequence\n",
    "for i in range(input_length):\n",
    "    targets[0][i]=input_sequence[0][i][1].item()-input_sequence[0][i][0].item()\n",
    "target_output = torch.from_numpy(targets)\n",
    "#target_output = torch.randn(batch_size,input_length,output_size)\n",
    "print('Target = ',target_output)\n",
    "print('Target Sum = ',torch.sum(target_output))\n",
    "num_epochs = 100\n",
    "\n",
    "#----------------------------------------\n",
    "# ----------------train-------------------\n",
    "#----------------------------------------\n",
    "pl_output = []\n",
    "pl_targets = []\n",
    "loss_vector = []\n",
    "for epoch in range(num_epochs):\n",
    "    rnn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs, hidden = rnn_model(input_sequence, hidden_state)\n",
    "    pl_output.append(outputs.item())\n",
    "    target_output1 = torch.sum(target_output) \n",
    "    loss = criterion(outputs, target_output)\n",
    "    pl_targets.append(target_output1)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vector.append(loss.item())\n",
    "    # Print the training loss for every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "##print('pl_output=',pl_output)\n",
    "#print('pl_targets=',pl_targets)\n",
    "# Plot the loss curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = torch.arange(0, num_epochs)\n",
    "plt.subplot(121)\n",
    "plt.plot(x_axis, loss_vector)\n",
    "plt.title('Loss in Vanilla RNN')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(x_axis,pl_output)\n",
    "plt.plot(x_axis, pl_targets)\n",
    "plt.title('Difference between output and targets')\n",
    "#----------------------------------------\n",
    "# ----------------test-------------------\n",
    "#----------------------------------------\n",
    "#evaluation mode\n",
    "rnn_model.eval()\n",
    "\n",
    "#forward pass on test input\n",
    "test_outputs, _ = rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0)))\n",
    "#print(rnn_model(input_sequence, rnn_model.init_hidden(input_sequence.size(0))))\n",
    "# Print the test outputs\n",
    "print(\"Test Outputs:\")\n",
    "print(test_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4996c735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\ASUS\\\\F.Champalimaud',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\python39.zip',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\ASUS\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdd8832",
   "metadata": {},
   "source": [
    "## --------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b44023",
   "metadata": {},
   "source": [
    "### other experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63f3070",
   "metadata": {},
   "source": [
    "## ----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d05fda",
   "metadata": {},
   "source": [
    "Define the ODE function:\n",
    "$\\dot{x}=-x+\\left [ Wx+b \\right ]_{+}$\n",
    "Where x is the hidden state, b is the bias, and $\\left [ \\cdot  \\right ]_{+}=max(0,\\cdot )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a201979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3997265   0.58227564  1.09807511  0.78365554 -0.48180916]\n",
      "Integrated output: [ 0.14706616  0.86011094  0.45784723  0.28832017 -0.17726577]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "#define the ODE function\n",
    "def ode_func(t, state, w, b):\n",
    "    wx_plus_b = np.maximum(0, np.dot(w, state) + b)\n",
    "    dstate_dt = -state + wx_plus_b\n",
    "    return dstate_dt\n",
    "\n",
    "#integration function\n",
    "def integrate_rnn_attractors(w, b, initial_state, t_start, t_end, num_points):\n",
    "    t_span = (t_start, t_end)\n",
    "    t_eval = np.linspace(t_start, t_end, num_points)\n",
    "\n",
    "    ode_args = (w, b)\n",
    "    solution = solve_ivp(ode_func, t_span, initial_state, t_eval=t_eval, args=ode_args)\n",
    "\n",
    "    return solution.t, solution.y\n",
    "\n",
    "#define parameters and initial conditions\n",
    "num_units = 5\n",
    "w = np.random.randn(num_units, num_units)  # Connectivity matrix\n",
    "#b = np.random.randn(num_units)  # Bias vector\n",
    "initial_state = np.random.randn(num_units)\n",
    "#initial_state = torch.randint(2, size=(1,num_units)).float()\n",
    "print(initial_state)\n",
    "\n",
    "#print(lele)\n",
    "t_start = 0\n",
    "t_end = 1\n",
    "num_points = 1000\n",
    "\n",
    "#integration\n",
    "t, state = integrate_rnn_attractors(w, b, initial_state, t_start, t_end, num_points)\n",
    "\n",
    "#result\n",
    "integrated_output = state[:, -1]\n",
    "print(\"Integrated output:\", integrated_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1529e3",
   "metadata": {},
   "source": [
    "for **unbounded line attractors (BLA)**, the W = $\\begin{bmatrix}\n",
    "0 & 1\\\\ 1 & 0\n",
    "\\end{bmatrix}$\n",
    "and b= 0. \n",
    "\n",
    "The resulting flow diverges to infinity along the diagonal. The backpropagating over time exponentially grows in magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f017cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrated output: [0. 0.]\n",
      "Integrated output: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def ode_func(t, state, b):\n",
    "    w = np.array([[0, 1], [1, 0]])\n",
    "    wx_plus_b = np.maximum(0, np.dot(w, state) + b)\n",
    "    dstate_dt = -state + wx_plus_b\n",
    "    return dstate_dt\n",
    "\n",
    "def integrate_rnn_attractors(b, initial_state, t_start, t_end, num_points):\n",
    "    t_span = (t_start, t_end)\n",
    "    t_eval = np.linspace(t_start, t_end, num_points)\n",
    "\n",
    "    ode_args = (b,)\n",
    "    solution = solve_ivp(ode_func, t_span, initial_state, t_eval=t_eval, args=ode_args)\n",
    "\n",
    "    return solution.t, solution.y\n",
    "\n",
    "num_units = 2\n",
    "b = 0  # Bias vector\n",
    "initial_state = np.zeros(num_units)\n",
    "t_start = 0\n",
    "t_end = 1\n",
    "num_points = 1000\n",
    "\n",
    "t, state = integrate_rnn_attractors(b, initial_state, t_start, t_end, num_points)\n",
    "\n",
    "integrated_output = state[:, -1]\n",
    "print(\"Integrated output:\", integrated_output)\n",
    "\n",
    "integrated_output = state[:, -1]\n",
    "print(\"Integrated output:\", integrated_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceba224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming test_input is the input sequence for testing\n",
    "test_input = test_input = torch.randn(sequence_length, input_size)  # Test input sequence\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "    test_input = torch.tensor(test_input, dtype=torch.float32)\n",
    "    predicted_output = model(test_input.unsqueeze(0).unsqueeze(0)).squeeze().numpy()\n",
    "\n",
    "    print(\"Predicted output:\", predicted_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c45a7396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Trial: tensor([0.])\n",
      "Target: tensor([[0.9264]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7572\\955524387.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype=torch.float32).unsqueeze(0)\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7572\\955524387.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 60>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(inputs, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     66\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(targets, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m     71\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mAttractorLSTM.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m c0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Pass through LSTM\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Apply ReLU and linear layer\u001b[39;00m\n\u001b[0;32m     47\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:803\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    801\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor unbatched 2-D input, hx and cx should \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malso be 2-D but got (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-D) tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 803\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg)\n\u001b[0;32m    804\u001b[0m         hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    806\u001b[0m \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    807\u001b[0m \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: For unbatched 2-D input, hx and cx should also be 2-D but got (3-D, 3-D) tensors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# number of trials and sequence length\n",
    "num_trials = 1000\n",
    "sequence_length = 1\n",
    "input_size = 1\n",
    "\n",
    "# Random sequence of 0 and 1\n",
    "input_trials = torch.randint(2, size=(num_trials, sequence_length)).float()\n",
    "\n",
    "# Generation of random input trials\n",
    "targets = []\n",
    "for _ in range(num_trials):\n",
    "    sequence = torch.randn(sequence_length, input_size)\n",
    "    # Cumulative sum of the sequence\n",
    "    target = torch.cumsum(sequence, dim=0)\n",
    "    targets.append(target)\n",
    "\n",
    "# Convert input trials and targets to tensors\n",
    "target_trials = torch.stack(targets).float()\n",
    "\n",
    "sample_index = 0\n",
    "print(\"Input Trial:\", input_trials[sample_index])\n",
    "print(\"Target:\", targets[sample_index])\n",
    "\n",
    "class AttractorLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(AttractorLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # get the batch size\n",
    "        # Initialize hidden and cell states\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Apply ReLU and linear layer\n",
    "        out = self.relu(out)\n",
    "        out = self.fc(out)\n",
    "        return out.squeeze(2)\n",
    "\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "\n",
    "model = AttractorLSTM(input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for inputs, targets in zip(input_trials, target_trials):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        inputs = torch.tensor(inputs, dtype=torch.float32).unsqueeze(0)\n",
    "        targets = torch.tensor(targets, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(input_trials)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22279276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
